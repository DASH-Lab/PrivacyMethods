{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 \n",
    "###### cifar-10 dataset 원본 위치: /media/data2/hyunjun/content/origin-cifar-10\n",
    "###### cifar-10 dataset svd 처리한 거 위치: /media/data2/hyunjun/content/svd-cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=10, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))\n",
    "])\n",
    "\n",
    "root = '' ## 이미지 경로\n",
    "\n",
    "original_trainset = datasets.ImageFolder(root=root+\"/origin-cifar-10/train\", transform=trans)\n",
    "original_testset = datasets.ImageFolder(root=root+\"origin-cifar-10/test\", transform=trans)\n",
    "svd_trainset = datasets.ImageFolder(root=root+\"/svd-cifar-10/train\", transform=trans)\n",
    "svd_testset = datasets.ImageFolder(root=root+\"/svd-cifar-10/test\", transform=trans)\n",
    "svd4_trainset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/train\", transform=trans)\n",
    "svd4_testset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/test\", transform=trans)\n",
    "\n",
    "o_trainloader = DataLoader(original_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "o_testloader = DataLoader(original_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s_trainloader = DataLoader(svd_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s_testloader = DataLoader(svd_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s4_trainloader = DataLoader(svd4_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s4_testloader = DataLoader(svd4_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "classes = original_testset.classes\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model1 = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model2 = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model3 = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "model1._fc = nn.Linear(in_features=model1._fc.in_features, out_features=10)\n",
    "model2._fc = nn.Linear(in_features=model2._fc.in_features, out_features=10)\n",
    "model3._fc = nn.Linear(in_features=model3._fc.in_features, out_features=10)\n",
    "nn.init.xavier_normal_(model1._fc.weight)\n",
    "nn.init.xavier_normal_(model2._fc.weight)\n",
    "nn.init.xavier_normal_(model3._fc.weight)\n",
    "\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=lr)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=lr)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=lr)\n",
    "\n",
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_sum = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.to(device))\n",
    "        loss = criterion(pred, y.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            loss_sum += loss\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss_sum / size\n",
    "\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    hit, loss = 0, 0\n",
    "    conf_matrix = []\n",
    "    for i in range(10):\n",
    "        conf_matrix.append([0, 0, 0, 0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            loss += criterion(pred, y.to(device)).item()\n",
    "            hit += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "            temp = pred.argmax(1)\n",
    "            for k in range(len(temp)):\n",
    "                for i in range(10):\n",
    "                    if i == temp[k]:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][0] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][1] += 1.0\n",
    "                    else:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][2] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][3] += 1.0\n",
    "    \n",
    "    loss /= (size/batch_size)\n",
    "    hit /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*hit):>0.1f}%, Avg loss: {loss:>8f}\\n\")\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.903020 [    0/50000]\n",
      "loss: 1.828581 [ 6400/50000]\n",
      "loss: 1.285742 [12800/50000]\n",
      "loss: 1.086572 [19200/50000]\n",
      "loss: 1.021788 [25600/50000]\n",
      "loss: 0.766840 [32000/50000]\n",
      "loss: 1.053449 [38400/50000]\n",
      "loss: 0.902497 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.739391\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.841636\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 1.434585\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.707691 [    0/50000]\n",
      "loss: 1.097934 [ 6400/50000]\n",
      "loss: 0.498116 [12800/50000]\n",
      "loss: 0.790496 [19200/50000]\n",
      "loss: 0.565366 [25600/50000]\n",
      "loss: 0.645308 [32000/50000]\n",
      "loss: 0.888303 [38400/50000]\n",
      "loss: 0.340562 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.696730\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.883601\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.732834\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.528202 [    0/50000]\n",
      "loss: 0.426532 [ 6400/50000]\n",
      "loss: 0.540750 [12800/50000]\n",
      "loss: 0.570562 [19200/50000]\n",
      "loss: 0.608099 [25600/50000]\n",
      "loss: 0.807439 [32000/50000]\n",
      "loss: 0.453122 [38400/50000]\n",
      "loss: 0.653493 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.616930\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.697494\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.298723\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.403385 [    0/50000]\n",
      "loss: 0.438006 [ 6400/50000]\n",
      "loss: 0.254788 [12800/50000]\n",
      "loss: 0.633521 [19200/50000]\n",
      "loss: 0.466870 [25600/50000]\n",
      "loss: 0.487785 [32000/50000]\n",
      "loss: 0.305144 [38400/50000]\n",
      "loss: 0.420882 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.607697\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.767232\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.437167\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.296939 [    0/50000]\n",
      "loss: 0.393464 [ 6400/50000]\n",
      "loss: 0.308740 [12800/50000]\n",
      "loss: 0.450422 [19200/50000]\n",
      "loss: 0.541196 [25600/50000]\n",
      "loss: 0.391847 [32000/50000]\n",
      "loss: 0.313183 [38400/50000]\n",
      "loss: 0.428053 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.616856\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.749833\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.465423\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.505544 [    0/50000]\n",
      "loss: 0.308004 [ 6400/50000]\n",
      "loss: 0.466438 [12800/50000]\n",
      "loss: 0.396163 [19200/50000]\n",
      "loss: 0.240107 [25600/50000]\n",
      "loss: 0.408533 [32000/50000]\n",
      "loss: 0.654114 [38400/50000]\n",
      "loss: 0.385737 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.609863\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.743333\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.378110\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.232767 [    0/50000]\n",
      "loss: 0.277248 [ 6400/50000]\n",
      "loss: 0.499535 [12800/50000]\n",
      "loss: 0.346609 [19200/50000]\n",
      "loss: 0.310557 [25600/50000]\n",
      "loss: 0.227743 [32000/50000]\n",
      "loss: 0.322238 [38400/50000]\n",
      "loss: 0.505639 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.666598\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.902577\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.746956\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.222978 [    0/50000]\n",
      "loss: 0.279856 [ 6400/50000]\n",
      "loss: 0.561253 [12800/50000]\n",
      "loss: 0.460392 [19200/50000]\n",
      "loss: 0.306630 [25600/50000]\n",
      "loss: 0.283693 [32000/50000]\n",
      "loss: 0.180033 [38400/50000]\n",
      "loss: 0.292259 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.655795\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.799328\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.635983\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.292102 [    0/50000]\n",
      "loss: 0.397514 [ 6400/50000]\n",
      "loss: 0.328310 [12800/50000]\n",
      "loss: 0.307518 [19200/50000]\n",
      "loss: 0.209001 [25600/50000]\n",
      "loss: 0.163926 [32000/50000]\n",
      "loss: 0.356066 [38400/50000]\n",
      "loss: 0.330757 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.682325\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.852023\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.727802\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.224629 [    0/50000]\n",
      "loss: 0.218023 [ 6400/50000]\n",
      "loss: 0.279722 [12800/50000]\n",
      "loss: 0.554330 [19200/50000]\n",
      "loss: 0.072872 [25600/50000]\n",
      "loss: 0.319523 [32000/50000]\n",
      "loss: 0.153662 [38400/50000]\n",
      "loss: 0.238699 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.687422\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.880729\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 1.854401\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.153181 [    0/50000]\n",
      "loss: 0.342188 [ 6400/50000]\n",
      "loss: 0.221199 [12800/50000]\n",
      "loss: 0.201975 [19200/50000]\n",
      "loss: 0.163165 [25600/50000]\n",
      "loss: 0.235887 [32000/50000]\n",
      "loss: 0.248488 [38400/50000]\n",
      "loss: 0.344768 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.699244\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.845725\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.757844\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.219179 [    0/50000]\n",
      "loss: 0.072750 [ 6400/50000]\n",
      "loss: 0.359910 [12800/50000]\n",
      "loss: 0.316557 [19200/50000]\n",
      "loss: 0.150505 [25600/50000]\n",
      "loss: 0.231045 [32000/50000]\n",
      "loss: 0.221628 [38400/50000]\n",
      "loss: 0.159230 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.669582\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.907667\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.885019\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.243559 [    0/50000]\n",
      "loss: 0.108509 [ 6400/50000]\n",
      "loss: 0.098891 [12800/50000]\n",
      "loss: 0.164646 [19200/50000]\n",
      "loss: 0.258412 [25600/50000]\n",
      "loss: 0.219813 [32000/50000]\n",
      "loss: 0.148535 [38400/50000]\n",
      "loss: 0.098611 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.709780\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.898384\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 1.703878\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.171095 [    0/50000]\n",
      "loss: 0.257507 [ 6400/50000]\n",
      "loss: 0.252984 [12800/50000]\n",
      "loss: 0.147375 [19200/50000]\n",
      "loss: 0.191960 [25600/50000]\n",
      "loss: 0.158800 [32000/50000]\n",
      "loss: 0.280797 [38400/50000]\n",
      "loss: 0.153016 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.723890\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.869975\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 1.752238\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.120882 [    0/50000]\n",
      "loss: 0.346793 [ 6400/50000]\n",
      "loss: 0.110646 [12800/50000]\n",
      "loss: 0.193380 [19200/50000]\n",
      "loss: 0.055317 [25600/50000]\n",
      "loss: 0.142337 [32000/50000]\n",
      "loss: 0.404653 [38400/50000]\n",
      "loss: 0.162933 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.795768\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.043384\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 2.144595\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.089648 [    0/50000]\n",
      "loss: 0.032293 [ 6400/50000]\n",
      "loss: 0.021609 [12800/50000]\n",
      "loss: 0.111626 [19200/50000]\n",
      "loss: 0.104134 [25600/50000]\n",
      "loss: 0.135604 [32000/50000]\n",
      "loss: 0.179242 [38400/50000]\n",
      "loss: 0.367253 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.757547\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.912324\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.871894\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.184491 [    0/50000]\n",
      "loss: 0.207804 [ 6400/50000]\n",
      "loss: 0.096649 [12800/50000]\n",
      "loss: 0.100322 [19200/50000]\n",
      "loss: 0.115742 [25600/50000]\n",
      "loss: 0.074503 [32000/50000]\n",
      "loss: 0.350489 [38400/50000]\n",
      "loss: 0.150259 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.778466\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.990202\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 1.923416\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.271331 [    0/50000]\n",
      "loss: 0.121588 [ 6400/50000]\n",
      "loss: 0.106608 [12800/50000]\n",
      "loss: 0.245607 [19200/50000]\n",
      "loss: 0.080365 [25600/50000]\n",
      "loss: 0.050336 [32000/50000]\n",
      "loss: 0.116358 [38400/50000]\n",
      "loss: 0.083560 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.766600\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.930583\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 1.921366\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.079901 [    0/50000]\n",
      "loss: 0.155991 [ 6400/50000]\n",
      "loss: 0.236758 [12800/50000]\n",
      "loss: 0.065466 [19200/50000]\n",
      "loss: 0.050040 [25600/50000]\n",
      "loss: 0.055965 [32000/50000]\n",
      "loss: 0.199856 [38400/50000]\n",
      "loss: 0.085761 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.767874\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.897287\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.934688\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.011392 [    0/50000]\n",
      "loss: 0.136804 [ 6400/50000]\n",
      "loss: 0.179368 [12800/50000]\n",
      "loss: 0.007413 [19200/50000]\n",
      "loss: 0.116160 [25600/50000]\n",
      "loss: 0.110655 [32000/50000]\n",
      "loss: 0.105558 [38400/50000]\n",
      "loss: 0.015451 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.866048\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.182190\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.294985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss1, test_res1, test_res2, test_res3 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model1.train()\n",
    "    train_loss1.append(train_loop(o_trainloader, model1, criterion, optimizer1))\n",
    "    model1.eval()\n",
    "    test_res1.append(test_loop(o_testloader, model1, criterion))\n",
    "    test_res2.append(test_loop(s_testloader, model1, criterion))\n",
    "    test_res3.append(test_loop(s4_testloader, model1, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.824425 [    0/50000]\n",
      "loss: 1.521721 [ 6400/50000]\n",
      "loss: 1.153502 [12800/50000]\n",
      "loss: 1.204732 [19200/50000]\n",
      "loss: 1.122265 [25600/50000]\n",
      "loss: 1.076364 [32000/50000]\n",
      "loss: 0.736479 [38400/50000]\n",
      "loss: 0.862050 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.882837\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.836010\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.228809\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.575866 [    0/50000]\n",
      "loss: 0.868848 [ 6400/50000]\n",
      "loss: 0.914497 [12800/50000]\n",
      "loss: 0.844224 [19200/50000]\n",
      "loss: 0.732538 [25600/50000]\n",
      "loss: 0.769383 [32000/50000]\n",
      "loss: 0.924691 [38400/50000]\n",
      "loss: 0.537381 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.756354\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.714184\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.200454\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.513569 [    0/50000]\n",
      "loss: 0.622715 [ 6400/50000]\n",
      "loss: 0.861878 [12800/50000]\n",
      "loss: 0.693696 [19200/50000]\n",
      "loss: 0.641764 [25600/50000]\n",
      "loss: 0.857621 [32000/50000]\n",
      "loss: 0.644816 [38400/50000]\n",
      "loss: 0.841352 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.678234\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.678020\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.105397\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.453542 [    0/50000]\n",
      "loss: 0.497030 [ 6400/50000]\n",
      "loss: 0.561451 [12800/50000]\n",
      "loss: 0.595645 [19200/50000]\n",
      "loss: 0.607299 [25600/50000]\n",
      "loss: 0.461252 [32000/50000]\n",
      "loss: 0.532360 [38400/50000]\n",
      "loss: 0.677169 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.797103\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.715201\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.079715\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.601097 [    0/50000]\n",
      "loss: 0.535142 [ 6400/50000]\n",
      "loss: 0.322930 [12800/50000]\n",
      "loss: 0.530429 [19200/50000]\n",
      "loss: 0.302328 [25600/50000]\n",
      "loss: 0.439257 [32000/50000]\n",
      "loss: 0.295301 [38400/50000]\n",
      "loss: 0.647012 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.627952\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.659266\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.288934\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.306588 [    0/50000]\n",
      "loss: 0.274360 [ 6400/50000]\n",
      "loss: 0.317741 [12800/50000]\n",
      "loss: 0.470528 [19200/50000]\n",
      "loss: 0.506994 [25600/50000]\n",
      "loss: 0.454970 [32000/50000]\n",
      "loss: 0.817131 [38400/50000]\n",
      "loss: 0.500918 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.704003\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.668988\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.060169\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.305534 [    0/50000]\n",
      "loss: 0.511273 [ 6400/50000]\n",
      "loss: 0.220386 [12800/50000]\n",
      "loss: 0.216862 [19200/50000]\n",
      "loss: 0.604581 [25600/50000]\n",
      "loss: 0.530662 [32000/50000]\n",
      "loss: 0.267327 [38400/50000]\n",
      "loss: 0.328817 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.739947\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.716881\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.184519\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.236843 [    0/50000]\n",
      "loss: 0.197712 [ 6400/50000]\n",
      "loss: 0.192184 [12800/50000]\n",
      "loss: 0.282015 [19200/50000]\n",
      "loss: 0.233036 [25600/50000]\n",
      "loss: 0.582620 [32000/50000]\n",
      "loss: 0.502783 [38400/50000]\n",
      "loss: 0.311760 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.714738\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.706994\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 1.227892\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.241287 [    0/50000]\n",
      "loss: 0.314370 [ 6400/50000]\n",
      "loss: 0.363895 [12800/50000]\n",
      "loss: 0.226761 [19200/50000]\n",
      "loss: 0.287157 [25600/50000]\n",
      "loss: 0.265407 [32000/50000]\n",
      "loss: 0.511616 [38400/50000]\n",
      "loss: 0.336492 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.635760\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.718154\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.508885\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.321108 [    0/50000]\n",
      "loss: 0.564075 [ 6400/50000]\n",
      "loss: 0.181874 [12800/50000]\n",
      "loss: 0.246017 [19200/50000]\n",
      "loss: 0.169900 [25600/50000]\n",
      "loss: 0.280186 [32000/50000]\n",
      "loss: 0.395043 [38400/50000]\n",
      "loss: 0.301531 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.745595\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.717648\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.299861\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.279940 [    0/50000]\n",
      "loss: 0.206026 [ 6400/50000]\n",
      "loss: 0.188376 [12800/50000]\n",
      "loss: 0.192383 [19200/50000]\n",
      "loss: 0.286635 [25600/50000]\n",
      "loss: 0.182810 [32000/50000]\n",
      "loss: 0.114871 [38400/50000]\n",
      "loss: 0.416169 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.701599\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.721509\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.393368\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.170485 [    0/50000]\n",
      "loss: 0.091374 [ 6400/50000]\n",
      "loss: 0.147031 [12800/50000]\n",
      "loss: 0.369324 [19200/50000]\n",
      "loss: 0.218244 [25600/50000]\n",
      "loss: 0.279108 [32000/50000]\n",
      "loss: 0.369616 [38400/50000]\n",
      "loss: 0.270984 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.942983\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.848780\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.280729\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.057776 [    0/50000]\n",
      "loss: 0.188666 [ 6400/50000]\n",
      "loss: 0.224235 [12800/50000]\n",
      "loss: 0.185645 [19200/50000]\n",
      "loss: 0.219317 [25600/50000]\n",
      "loss: 0.127873 [32000/50000]\n",
      "loss: 0.154128 [38400/50000]\n",
      "loss: 0.233836 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.789354\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.826392\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.493118\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.188088 [    0/50000]\n",
      "loss: 0.181343 [ 6400/50000]\n",
      "loss: 0.071797 [12800/50000]\n",
      "loss: 0.394257 [19200/50000]\n",
      "loss: 0.210424 [25600/50000]\n",
      "loss: 0.305935 [32000/50000]\n",
      "loss: 0.166531 [38400/50000]\n",
      "loss: 0.286096 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.798532\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.778063\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.342643\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.050826 [    0/50000]\n",
      "loss: 0.029453 [ 6400/50000]\n",
      "loss: 0.351144 [12800/50000]\n",
      "loss: 0.091224 [19200/50000]\n",
      "loss: 0.272377 [25600/50000]\n",
      "loss: 0.037712 [32000/50000]\n",
      "loss: 0.291369 [38400/50000]\n",
      "loss: 0.131544 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.855293\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.887168\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.585474\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.033056 [    0/50000]\n",
      "loss: 0.150603 [ 6400/50000]\n",
      "loss: 0.106186 [12800/50000]\n",
      "loss: 0.154685 [19200/50000]\n",
      "loss: 0.268708 [25600/50000]\n",
      "loss: 0.237123 [32000/50000]\n",
      "loss: 0.245735 [38400/50000]\n",
      "loss: 0.220416 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.819955\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.853055\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.561851\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.259158 [    0/50000]\n",
      "loss: 0.184396 [ 6400/50000]\n",
      "loss: 0.073284 [12800/50000]\n",
      "loss: 0.133908 [19200/50000]\n",
      "loss: 0.146230 [25600/50000]\n",
      "loss: 0.046179 [32000/50000]\n",
      "loss: 0.075061 [38400/50000]\n",
      "loss: 0.038990 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.837192\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.843361\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.586231\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.027989 [    0/50000]\n",
      "loss: 0.237050 [ 6400/50000]\n",
      "loss: 0.107181 [12800/50000]\n",
      "loss: 0.289019 [19200/50000]\n",
      "loss: 0.077536 [25600/50000]\n",
      "loss: 0.103521 [32000/50000]\n",
      "loss: 0.286241 [38400/50000]\n",
      "loss: 0.401591 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.839295\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.813729\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 1.418787\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.047684 [    0/50000]\n",
      "loss: 0.229936 [ 6400/50000]\n",
      "loss: 0.156279 [12800/50000]\n",
      "loss: 0.047695 [19200/50000]\n",
      "loss: 0.254274 [25600/50000]\n",
      "loss: 0.164526 [32000/50000]\n",
      "loss: 0.110562 [38400/50000]\n",
      "loss: 0.335238 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.881983\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.855978\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 1.520865\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.136514 [    0/50000]\n",
      "loss: 0.201429 [ 6400/50000]\n",
      "loss: 0.113102 [12800/50000]\n",
      "loss: 0.161329 [19200/50000]\n",
      "loss: 0.153840 [25600/50000]\n",
      "loss: 0.085542 [32000/50000]\n",
      "loss: 0.239317 [38400/50000]\n",
      "loss: 0.149182 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.942640\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.910512\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.546048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss2, test_res4, test_res5, test_res6 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model2.train()\n",
    "    train_loss2.append(train_loop(s_trainloader, model2, criterion, optimizer2))\n",
    "    model2.eval()\n",
    "    test_res4.append(test_loop(o_testloader, model2, criterion))\n",
    "    test_res5.append(test_loop(s_testloader, model2, criterion))\n",
    "    test_res6.append(test_loop(s4_testloader, model2, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.601522 [    0/50000]\n",
      "loss: 1.739254 [ 6400/50000]\n",
      "loss: 1.475773 [12800/50000]\n",
      "loss: 1.229420 [19200/50000]\n",
      "loss: 0.995757 [25600/50000]\n",
      "loss: 1.222319 [32000/50000]\n",
      "loss: 1.214512 [38400/50000]\n",
      "loss: 0.989437 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 1.231928\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.073367\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.042639\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 1.002802 [    0/50000]\n",
      "loss: 0.923861 [ 6400/50000]\n",
      "loss: 0.862455 [12800/50000]\n",
      "loss: 1.116309 [19200/50000]\n",
      "loss: 0.816272 [25600/50000]\n",
      "loss: 1.049231 [32000/50000]\n",
      "loss: 0.791166 [38400/50000]\n",
      "loss: 0.768443 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.235885\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.974167\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.898509\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.837048 [    0/50000]\n",
      "loss: 0.670986 [ 6400/50000]\n",
      "loss: 0.666613 [12800/50000]\n",
      "loss: 0.510436 [19200/50000]\n",
      "loss: 0.566297 [25600/50000]\n",
      "loss: 0.645721 [32000/50000]\n",
      "loss: 0.719834 [38400/50000]\n",
      "loss: 0.668025 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.992877\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.856624\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.852424\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.513234 [    0/50000]\n",
      "loss: 0.656513 [ 6400/50000]\n",
      "loss: 0.600941 [12800/50000]\n",
      "loss: 0.814395 [19200/50000]\n",
      "loss: 0.789717 [25600/50000]\n",
      "loss: 0.610125 [32000/50000]\n",
      "loss: 0.595675 [38400/50000]\n",
      "loss: 0.537951 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.095497\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.903966\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.873485\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.665459 [    0/50000]\n",
      "loss: 0.371163 [ 6400/50000]\n",
      "loss: 0.497269 [12800/50000]\n",
      "loss: 0.901106 [19200/50000]\n",
      "loss: 0.865056 [25600/50000]\n",
      "loss: 0.609017 [32000/50000]\n",
      "loss: 0.604347 [38400/50000]\n",
      "loss: 0.642991 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.953849\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.828858\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.848125\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.420823 [    0/50000]\n",
      "loss: 0.754127 [ 6400/50000]\n",
      "loss: 0.519633 [12800/50000]\n",
      "loss: 0.577020 [19200/50000]\n",
      "loss: 0.575735 [25600/50000]\n",
      "loss: 0.910124 [32000/50000]\n",
      "loss: 0.544693 [38400/50000]\n",
      "loss: 0.388347 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.201020\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.992124\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.881910\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.582723 [    0/50000]\n",
      "loss: 0.452992 [ 6400/50000]\n",
      "loss: 0.559324 [12800/50000]\n",
      "loss: 0.697637 [19200/50000]\n",
      "loss: 0.752437 [25600/50000]\n",
      "loss: 0.261364 [32000/50000]\n",
      "loss: 0.458939 [38400/50000]\n",
      "loss: 0.681557 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.056706\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.910948\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.861985\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.298514 [    0/50000]\n",
      "loss: 0.534923 [ 6400/50000]\n",
      "loss: 0.371334 [12800/50000]\n",
      "loss: 0.549453 [19200/50000]\n",
      "loss: 0.374294 [25600/50000]\n",
      "loss: 0.506321 [32000/50000]\n",
      "loss: 0.440059 [38400/50000]\n",
      "loss: 0.384726 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.083797\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.904413\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.870509\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.344332 [    0/50000]\n",
      "loss: 0.422691 [ 6400/50000]\n",
      "loss: 0.582233 [12800/50000]\n",
      "loss: 0.342749 [19200/50000]\n",
      "loss: 0.503917 [25600/50000]\n",
      "loss: 0.421222 [32000/50000]\n",
      "loss: 0.368542 [38400/50000]\n",
      "loss: 0.288058 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.991565\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.875948\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.893169\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.295335 [    0/50000]\n",
      "loss: 0.502227 [ 6400/50000]\n",
      "loss: 0.178561 [12800/50000]\n",
      "loss: 0.546983 [19200/50000]\n",
      "loss: 0.337640 [25600/50000]\n",
      "loss: 0.368521 [32000/50000]\n",
      "loss: 0.366007 [38400/50000]\n",
      "loss: 0.291971 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.985412\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.851722\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.887866\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.304410 [    0/50000]\n",
      "loss: 0.446797 [ 6400/50000]\n",
      "loss: 0.404733 [12800/50000]\n",
      "loss: 0.385388 [19200/50000]\n",
      "loss: 0.258587 [25600/50000]\n",
      "loss: 0.250765 [32000/50000]\n",
      "loss: 0.288628 [38400/50000]\n",
      "loss: 0.259371 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.199352\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.994397\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.940622\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.155806 [    0/50000]\n",
      "loss: 0.217662 [ 6400/50000]\n",
      "loss: 0.251231 [12800/50000]\n",
      "loss: 0.308442 [19200/50000]\n",
      "loss: 0.204726 [25600/50000]\n",
      "loss: 0.269285 [32000/50000]\n",
      "loss: 0.437728 [38400/50000]\n",
      "loss: 0.286300 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.197286\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 1.050488\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.992483\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.188546 [    0/50000]\n",
      "loss: 0.303533 [ 6400/50000]\n",
      "loss: 0.284151 [12800/50000]\n",
      "loss: 0.274349 [19200/50000]\n",
      "loss: 0.375323 [25600/50000]\n",
      "loss: 0.211665 [32000/50000]\n",
      "loss: 0.233150 [38400/50000]\n",
      "loss: 0.316142 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.388803\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.148849\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 1.014944\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.169009 [    0/50000]\n",
      "loss: 0.202997 [ 6400/50000]\n",
      "loss: 0.237339 [12800/50000]\n",
      "loss: 0.247970 [19200/50000]\n",
      "loss: 0.128420 [25600/50000]\n",
      "loss: 0.121544 [32000/50000]\n",
      "loss: 0.381281 [38400/50000]\n",
      "loss: 0.477323 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.166564\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 1.034692\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 1.026490\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.114423 [    0/50000]\n",
      "loss: 0.162927 [ 6400/50000]\n",
      "loss: 0.236805 [12800/50000]\n",
      "loss: 0.298720 [19200/50000]\n",
      "loss: 0.334596 [25600/50000]\n",
      "loss: 0.211672 [32000/50000]\n",
      "loss: 0.103955 [38400/50000]\n",
      "loss: 0.148292 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.277646\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 1.102529\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 1.057036\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.083363 [    0/50000]\n",
      "loss: 0.180617 [ 6400/50000]\n",
      "loss: 0.258091 [12800/50000]\n",
      "loss: 0.224486 [19200/50000]\n",
      "loss: 0.169365 [25600/50000]\n",
      "loss: 0.267996 [32000/50000]\n",
      "loss: 0.218267 [38400/50000]\n",
      "loss: 0.070293 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 1.170293\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.030904\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.061669\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.116610 [    0/50000]\n",
      "loss: 0.296833 [ 6400/50000]\n",
      "loss: 0.144405 [12800/50000]\n",
      "loss: 0.348545 [19200/50000]\n",
      "loss: 0.303982 [25600/50000]\n",
      "loss: 0.152373 [32000/50000]\n",
      "loss: 0.098388 [38400/50000]\n",
      "loss: 0.308465 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.591346\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.325565\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 1.148901\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.237218 [    0/50000]\n",
      "loss: 0.146745 [ 6400/50000]\n",
      "loss: 0.160904 [12800/50000]\n",
      "loss: 0.233422 [19200/50000]\n",
      "loss: 0.159442 [25600/50000]\n",
      "loss: 0.153901 [32000/50000]\n",
      "loss: 0.232553 [38400/50000]\n",
      "loss: 0.130151 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.278773\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 1.081775\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.085826\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.164072 [    0/50000]\n",
      "loss: 0.127978 [ 6400/50000]\n",
      "loss: 0.217035 [12800/50000]\n",
      "loss: 0.070204 [19200/50000]\n",
      "loss: 0.199209 [25600/50000]\n",
      "loss: 0.367217 [32000/50000]\n",
      "loss: 0.246227 [38400/50000]\n",
      "loss: 0.169457 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.446992\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 1.230975\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.174458\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.226721 [    0/50000]\n",
      "loss: 0.157768 [ 6400/50000]\n",
      "loss: 0.204286 [12800/50000]\n",
      "loss: 0.170280 [19200/50000]\n",
      "loss: 0.265938 [25600/50000]\n",
      "loss: 0.347264 [32000/50000]\n",
      "loss: 0.200677 [38400/50000]\n",
      "loss: 0.158298 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.438343\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.223979\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 1.157375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss3, test_res7, test_res8, test_res9 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model3.train()\n",
    "    train_loss3.append(train_loop(s4_trainloader, model3, criterion, optimizer3))\n",
    "    model3.eval()\n",
    "    test_res7.append(test_loop(o_testloader, model3, criterion))\n",
    "    test_res8.append(test_loop(s_testloader, model3, criterion))\n",
    "    test_res9.append(test_loop(s4_testloader, model3, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for Testing with original datasets\n",
      "[[895.0, 326.0, 105.0, 8674.0], [914.0, 140.0, 86.0, 8860.0], [718.0, 279.0, 282.0, 8721.0], [614.0, 328.0, 386.0, 8672.0], [712.0, 194.0, 288.0, 8806.0], [675.0, 205.0, 325.0, 8795.0], [856.0, 195.0, 144.0, 8805.0], [839.0, 158.0, 161.0, 8842.0], [850.0, 79.0, 150.0, 8921.0], [868.0, 155.0, 132.0, 8845.0]] [[855.0, 252.0, 145.0, 8748.0], [782.0, 70.0, 218.0, 8930.0], [721.0, 280.0, 279.0, 8720.0], [615.0, 415.0, 385.0, 8585.0], [733.0, 266.0, 267.0, 8734.0], [699.0, 372.0, 301.0, 8628.0], [700.0, 86.0, 300.0, 8914.0], [858.0, 200.0, 142.0, 8800.0], [874.0, 119.0, 126.0, 8881.0], [871.0, 232.0, 129.0, 8768.0]] [[636.0, 293.0, 364.0, 8707.0], [368.0, 31.0, 632.0, 8969.0], [670.0, 616.0, 330.0, 8384.0], [535.0, 825.0, 465.0, 8175.0], [631.0, 531.0, 369.0, 8469.0], [446.0, 320.0, 554.0, 8680.0], [149.0, 15.0, 851.0, 8985.0], [667.0, 267.0, 333.0, 8733.0], [856.0, 597.0, 144.0, 8403.0], [809.0, 738.0, 191.0, 8262.0]]\n",
      "Result for Testing with original datasets\n",
      "[[927.0, 444.0, 73.0, 8556.0], [927.0, 192.0, 73.0, 8808.0], [721.0, 289.0, 279.0, 8711.0], [581.0, 281.0, 419.0, 8719.0], [732.0, 191.0, 268.0, 8809.0], [655.0, 195.0, 345.0, 8805.0], [884.0, 316.0, 116.0, 8684.0], [789.0, 97.0, 211.0, 8903.0], [773.0, 61.0, 227.0, 8939.0], [833.0, 112.0, 167.0, 8888.0]] [[892.0, 347.0, 108.0, 8653.0], [867.0, 119.0, 133.0, 8881.0], [690.0, 243.0, 310.0, 8757.0], [599.0, 335.0, 401.0, 8665.0], [797.0, 288.0, 203.0, 8712.0], [683.0, 243.0, 317.0, 8757.0], [821.0, 199.0, 179.0, 8801.0], [800.0, 121.0, 200.0, 8879.0], [804.0, 75.0, 196.0, 8925.0], [874.0, 203.0, 126.0, 8797.0]] [[729.0, 257.0, 271.0, 8743.0], [655.0, 67.0, 345.0, 8933.0], [667.0, 449.0, 333.0, 8551.0], [544.0, 627.0, 456.0, 8373.0], [554.0, 263.0, 446.0, 8737.0], [645.0, 525.0, 355.0, 8475.0], [552.0, 115.0, 448.0, 8885.0], [690.0, 194.0, 310.0, 8806.0], [879.0, 414.0, 121.0, 8586.0], [802.0, 372.0, 198.0, 8628.0]]\n",
      "Result for Testing with original datasets\n",
      "[[885.0, 676.0, 115.0, 8324.0], [902.0, 461.0, 98.0, 8539.0], [767.0, 876.0, 233.0, 8124.0], [426.0, 337.0, 574.0, 8663.0], [496.0, 157.0, 504.0, 8843.0], [366.0, 98.0, 634.0, 8902.0], [825.0, 429.0, 175.0, 8571.0], [628.0, 96.0, 372.0, 8904.0], [752.0, 230.0, 248.0, 8770.0], [551.0, 42.0, 449.0, 8958.0]] [[881.0, 485.0, 119.0, 8515.0], [925.0, 328.0, 75.0, 8672.0], [702.0, 373.0, 298.0, 8627.0], [480.0, 317.0, 520.0, 8683.0], [386.0, 36.0, 614.0, 8964.0], [682.0, 386.0, 318.0, 8614.0], [870.0, 429.0, 130.0, 8571.0], [804.0, 226.0, 196.0, 8774.0], [759.0, 75.0, 241.0, 8925.0], [744.0, 112.0, 256.0, 8888.0]] [[835.0, 324.0, 165.0, 8676.0], [860.0, 218.0, 140.0, 8782.0], [672.0, 324.0, 328.0, 8676.0], [569.0, 470.0, 431.0, 8530.0], [518.0, 99.0, 482.0, 8901.0], [715.0, 535.0, 285.0, 8465.0], [793.0, 283.0, 207.0, 8717.0], [784.0, 209.0, 216.0, 8791.0], [781.0, 81.0, 219.0, 8919.0], [783.0, 147.0, 217.0, 8853.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res1), max(test_res2), max(test_res3))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res4), max(test_res5), max(test_res6))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res7), max(test_res8), max(test_res9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_acc_finder(test_res):\n",
    "    best, max = 0, 0\n",
    "    for i in range(len(test_res)):\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for j in range(len(test_res[i])):\n",
    "            correct = test_res[i][j][0] +  test_res[i][j][3]\n",
    "            total = correct + test_res[i][j][2] + test_res[i][j][1]\n",
    "            if max < (correct / total):\n",
    "                max = correct / total\n",
    "                best = i\n",
    "\n",
    "    print(f\"best accuary: {max:>0.2f} at {best}\")\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 15\n",
      "best accuary: 0.98 at 15\n",
      "best accuary: 0.95 at 2\n",
      "best accuary: 0.98 at 14\n",
      "best accuary: 0.98 at 15\n",
      "best accuary: 0.96 at 7\n",
      "best accuary: 0.97 at 13\n",
      "best accuary: 0.97 at 13\n",
      "best accuary: 0.97 at 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_finder(test_res1)\n",
    "best_acc_finder(test_res2)\n",
    "best_acc_finder(test_res3)\n",
    "best_acc_finder(test_res4)\n",
    "best_acc_finder(test_res5)\n",
    "best_acc_finder(test_res6)\n",
    "best_acc_finder(test_res7)\n",
    "best_acc_finder(test_res8)\n",
    "best_acc_finder(test_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 15\n",
      "(0.9616199999999999, 0.8187222334212299, 0.8080999999999999, 0.8098547825669309)\n",
      "best accuary: 0.98 at 15\n",
      "(0.95404, 0.7869108906626759, 0.7702, 0.773668695641539)\n",
      "best accuary: 0.95 at 2\n",
      "(0.9166000000000001, 0.6544054866156535, 0.583, 0.5664532632586912)\n",
      "best accuary: 0.98 at 14\n",
      "(0.9577199999999999, 0.7977390132012483, 0.7886, 0.7889599638747092)\n",
      "best accuary: 0.98 at 15\n",
      "(0.95666, 0.7948065138701295, 0.7833, 0.7860066290166191)\n",
      "best accuary: 0.96 at 7\n",
      "(0.9317599999999999, 0.6905009029443699, 0.6588, 0.6577239086128633)\n",
      "best accuary: 0.97 at 13\n",
      "(0.9429599999999999, 0.7365213162742352, 0.7148000000000001, 0.7112990878830537)\n",
      "best accuary: 0.97 at 13\n",
      "(0.9476800000000001, 0.7500167013281633, 0.7384000000000001, 0.7364707890769435)\n",
      "best accuary: 0.97 at 13\n",
      "(0.9465, 0.7423803817375129, 0.7325, 0.7344577472568428)\n"
     ]
    }
   ],
   "source": [
    "def metrics_single_class(conf_mat):\n",
    "    accuracy = (conf_mat[0] + conf_mat[3]) / (conf_mat[0] + conf_mat[1] + conf_mat[2] + conf_mat[3])\n",
    "    precision = conf_mat[0] / (conf_mat[0] + conf_mat[1])\n",
    "    recall = conf_mat[0] / (conf_mat[0] + conf_mat[2])\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def metrics(conf_mats):\n",
    "    sum_acc, sum_pre, sum_recall, sum_f1 = 0.0, 0.0, 0.0, 0.0\n",
    "    for i in range(len(conf_mats)):\n",
    "        temp_acc, temp_pre, temp_recall, temp_f1 = metrics_single_class(conf_mats[i])\n",
    "        #print(f\"For class-{i}:\\n Accuracy: {temp_acc:>0.4f}, Precision: {temp_pre:>0.4f}, Recall: {temp_recall:>0.4f}, F1-score: {temp_f1:>0.4f}\")\n",
    "        sum_acc += temp_acc\n",
    "        sum_pre += temp_pre\n",
    "        sum_recall += temp_recall\n",
    "        sum_f1 += temp_f1\n",
    "\n",
    "    sum_acc /= 10\n",
    "    sum_pre /= 10\n",
    "    sum_recall /= 10\n",
    "    sum_f1 /= 10\n",
    "\n",
    "    return sum_acc, sum_pre, sum_recall, sum_f1\n",
    "\n",
    "\n",
    "print(metrics(test_res1[best_acc_finder(test_res1)]))\n",
    "print(metrics(test_res2[best_acc_finder(test_res2)]))\n",
    "print(metrics(test_res3[best_acc_finder(test_res3)]))\n",
    "print(metrics(test_res4[best_acc_finder(test_res4)]))\n",
    "print(metrics(test_res5[best_acc_finder(test_res5)]))\n",
    "print(metrics(test_res6[best_acc_finder(test_res6)]))\n",
    "print(metrics(test_res7[best_acc_finder(test_res7)]))\n",
    "print(metrics(test_res8[best_acc_finder(test_res8)]))\n",
    "print(metrics(test_res9[best_acc_finder(test_res9)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bc9c0d9ed678a9439887435d1dc6423dbc20cda066c045b53c2a9575a7c6ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
