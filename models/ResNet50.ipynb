{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))\n",
    "])\n",
    "\n",
    "root = '' ## 이미지 경로\n",
    "\n",
    "original_trainset = datasets.ImageFolder(root=root+\"/origin-cifar-10/train\", transform=trans)\n",
    "original_testset = datasets.ImageFolder(root=root+\"origin-cifar-10/test\", transform=trans)\n",
    "svd_trainset = datasets.ImageFolder(root=root+\"/svd-cifar-10/train\", transform=trans)\n",
    "svd_testset = datasets.ImageFolder(root=root+\"/svd-cifar-10/test\", transform=trans)\n",
    "svd4_trainset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/train\", transform=trans)\n",
    "svd4_testset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/test\", transform=trans)\n",
    "\n",
    "o_trainloader = DataLoader(original_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "o_testloader = DataLoader(original_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s_trainloader = DataLoader(svd_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s_testloader = DataLoader(svd_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s4_trainloader = DataLoader(svd4_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s4_testloader = DataLoader(svd4_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model1 = models.resnet50(weights=models.resnet.ResNet50_Weights.DEFAULT)\n",
    "model2 = models.resnet50(weights=models.resnet.ResNet50_Weights.DEFAULT)\n",
    "model3 = models.resnet50(weights=models.resnet.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "model1.fc = nn.Linear(in_features=model1.fc.in_features, out_features=10, bias=True)\n",
    "model2.fc = nn.Linear(in_features=model2.fc.in_features, out_features=10, bias=True)\n",
    "model3.fc = nn.Linear(in_features=model3.fc.in_features, out_features=10, bias=True)\n",
    "\n",
    "nn.init.xavier_normal_(model1.fc.weight)\n",
    "nn.init.xavier_normal_(model2.fc.weight)\n",
    "nn.init.xavier_normal_(model3.fc.weight)\n",
    "\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=lr)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=lr)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_sum = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.to(device))\n",
    "        loss = criterion(pred, y.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            loss_sum += loss\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss_sum / size\n",
    "\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    hit, loss = 0, 0\n",
    "    conf_matrix = []\n",
    "    for i in range(10):\n",
    "        conf_matrix.append([0, 0, 0, 0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            loss += criterion(pred, y.to(device)).item()\n",
    "            hit += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "            temp = pred.argmax(1)\n",
    "            for k in range(len(temp)):\n",
    "                for i in range(10):\n",
    "                    if i == temp[k]:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][0] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][1] += 1.0\n",
    "                    else:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][2] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][3] += 1.0\n",
    "    \n",
    "    loss /= (size/batch_size)\n",
    "    hit /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*hit):>0.1f}%, Avg loss: {loss:>8f}\\n\")\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.418232 [    0/50000]\n",
      "loss: 1.355377 [ 6400/50000]\n",
      "loss: 1.277040 [12800/50000]\n",
      "loss: 0.861599 [19200/50000]\n",
      "loss: 0.791579 [25600/50000]\n",
      "loss: 1.100408 [32000/50000]\n",
      "loss: 0.749126 [38400/50000]\n",
      "loss: 0.775429 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.891803\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.905745\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 1.335825\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 1.003006 [    0/50000]\n",
      "loss: 0.615579 [ 6400/50000]\n",
      "loss: 0.607499 [12800/50000]\n",
      "loss: 0.690856 [19200/50000]\n",
      "loss: 0.618476 [25600/50000]\n",
      "loss: 0.739790 [32000/50000]\n",
      "loss: 0.489801 [38400/50000]\n",
      "loss: 0.842935 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.598736\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.681695\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.169243\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.303176 [    0/50000]\n",
      "loss: 0.403631 [ 6400/50000]\n",
      "loss: 0.375007 [12800/50000]\n",
      "loss: 0.412683 [19200/50000]\n",
      "loss: 0.480350 [25600/50000]\n",
      "loss: 0.513973 [32000/50000]\n",
      "loss: 0.644102 [38400/50000]\n",
      "loss: 0.680310 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.597591\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.711012\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.257814\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.362364 [    0/50000]\n",
      "loss: 0.336492 [ 6400/50000]\n",
      "loss: 0.675227 [12800/50000]\n",
      "loss: 0.330740 [19200/50000]\n",
      "loss: 0.281188 [25600/50000]\n",
      "loss: 0.363918 [32000/50000]\n",
      "loss: 0.400838 [38400/50000]\n",
      "loss: 0.478681 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.619085\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.787610\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 1.445164\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.348801 [    0/50000]\n",
      "loss: 0.212902 [ 6400/50000]\n",
      "loss: 0.328893 [12800/50000]\n",
      "loss: 0.433756 [19200/50000]\n",
      "loss: 0.440063 [25600/50000]\n",
      "loss: 0.524837 [32000/50000]\n",
      "loss: 0.429251 [38400/50000]\n",
      "loss: 0.557575 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.619480\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.778220\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.712355\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.287449 [    0/50000]\n",
      "loss: 0.177292 [ 6400/50000]\n",
      "loss: 0.550530 [12800/50000]\n",
      "loss: 0.436303 [19200/50000]\n",
      "loss: 0.221602 [25600/50000]\n",
      "loss: 0.443572 [32000/50000]\n",
      "loss: 0.136940 [38400/50000]\n",
      "loss: 0.541114 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.571015\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.734125\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 1.424556\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.181319 [    0/50000]\n",
      "loss: 0.297431 [ 6400/50000]\n",
      "loss: 0.198877 [12800/50000]\n",
      "loss: 0.170741 [19200/50000]\n",
      "loss: 0.161369 [25600/50000]\n",
      "loss: 0.441943 [32000/50000]\n",
      "loss: 0.161158 [38400/50000]\n",
      "loss: 0.181039 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.614791\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.808612\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.575344\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.126604 [    0/50000]\n",
      "loss: 0.125998 [ 6400/50000]\n",
      "loss: 0.351389 [12800/50000]\n",
      "loss: 0.131335 [19200/50000]\n",
      "loss: 0.279362 [25600/50000]\n",
      "loss: 0.411604 [32000/50000]\n",
      "loss: 0.205678 [38400/50000]\n",
      "loss: 0.355714 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.608899\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.792982\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.520675\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.078426 [    0/50000]\n",
      "loss: 0.198383 [ 6400/50000]\n",
      "loss: 0.329746 [12800/50000]\n",
      "loss: 0.257019 [19200/50000]\n",
      "loss: 0.149369 [25600/50000]\n",
      "loss: 0.187423 [32000/50000]\n",
      "loss: 0.332024 [38400/50000]\n",
      "loss: 0.167977 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.680810\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.921691\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 1.712015\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.140627 [    0/50000]\n",
      "loss: 0.353234 [ 6400/50000]\n",
      "loss: 0.068712 [12800/50000]\n",
      "loss: 0.284314 [19200/50000]\n",
      "loss: 0.300585 [25600/50000]\n",
      "loss: 0.125413 [32000/50000]\n",
      "loss: 0.079850 [38400/50000]\n",
      "loss: 0.133886 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.663693\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.823074\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.809432\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.078778 [    0/50000]\n",
      "loss: 0.082202 [ 6400/50000]\n",
      "loss: 0.154263 [12800/50000]\n",
      "loss: 0.130124 [19200/50000]\n",
      "loss: 0.263279 [25600/50000]\n",
      "loss: 0.055784 [32000/50000]\n",
      "loss: 0.071800 [38400/50000]\n",
      "loss: 0.318103 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.665682\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.799659\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.585507\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.296231 [    0/50000]\n",
      "loss: 0.076448 [ 6400/50000]\n",
      "loss: 0.158526 [12800/50000]\n",
      "loss: 0.101871 [19200/50000]\n",
      "loss: 0.069526 [25600/50000]\n",
      "loss: 0.179238 [32000/50000]\n",
      "loss: 0.188072 [38400/50000]\n",
      "loss: 0.132999 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.698670\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.879740\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.835107\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.108419 [    0/50000]\n",
      "loss: 0.160107 [ 6400/50000]\n",
      "loss: 0.156773 [12800/50000]\n",
      "loss: 0.138281 [19200/50000]\n",
      "loss: 0.080525 [25600/50000]\n",
      "loss: 0.087514 [32000/50000]\n",
      "loss: 0.074196 [38400/50000]\n",
      "loss: 0.175851 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.651047\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.835806\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 1.776578\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.041838 [    0/50000]\n",
      "loss: 0.156970 [ 6400/50000]\n",
      "loss: 0.145215 [12800/50000]\n",
      "loss: 0.019805 [19200/50000]\n",
      "loss: 0.043846 [25600/50000]\n",
      "loss: 0.232233 [32000/50000]\n",
      "loss: 0.112126 [38400/50000]\n",
      "loss: 0.127807 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.987339\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.088490\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.912986\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.125592 [    0/50000]\n",
      "loss: 0.159645 [ 6400/50000]\n",
      "loss: 0.324627 [12800/50000]\n",
      "loss: 0.156584 [19200/50000]\n",
      "loss: 0.202355 [25600/50000]\n",
      "loss: 0.019046 [32000/50000]\n",
      "loss: 0.026454 [38400/50000]\n",
      "loss: 0.120647 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.688545\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.833753\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.841293\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.037247 [    0/50000]\n",
      "loss: 0.027671 [ 6400/50000]\n",
      "loss: 0.104164 [12800/50000]\n",
      "loss: 0.065366 [19200/50000]\n",
      "loss: 0.127551 [25600/50000]\n",
      "loss: 0.190141 [32000/50000]\n",
      "loss: 0.013773 [38400/50000]\n",
      "loss: 0.112369 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.731469\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.973488\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 2.031664\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.049920 [    0/50000]\n",
      "loss: 0.084984 [ 6400/50000]\n",
      "loss: 0.007989 [12800/50000]\n",
      "loss: 0.063338 [19200/50000]\n",
      "loss: 0.108835 [25600/50000]\n",
      "loss: 0.015070 [32000/50000]\n",
      "loss: 0.171045 [38400/50000]\n",
      "loss: 0.066319 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.728054\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.937351\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.750696\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.014758 [    0/50000]\n",
      "loss: 0.031366 [ 6400/50000]\n",
      "loss: 0.060569 [12800/50000]\n",
      "loss: 0.006592 [19200/50000]\n",
      "loss: 0.084757 [25600/50000]\n",
      "loss: 0.040625 [32000/50000]\n",
      "loss: 0.023732 [38400/50000]\n",
      "loss: 0.154812 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.746411\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.900379\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 1.870288\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.086091 [    0/50000]\n",
      "loss: 0.104629 [ 6400/50000]\n",
      "loss: 0.019063 [12800/50000]\n",
      "loss: 0.043565 [19200/50000]\n",
      "loss: 0.074727 [25600/50000]\n",
      "loss: 0.054264 [32000/50000]\n",
      "loss: 0.040090 [38400/50000]\n",
      "loss: 0.048611 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.737994\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.937523\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 1.956449\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.007431 [    0/50000]\n",
      "loss: 0.184435 [ 6400/50000]\n",
      "loss: 0.046662 [12800/50000]\n",
      "loss: 0.021364 [19200/50000]\n",
      "loss: 0.034644 [25600/50000]\n",
      "loss: 0.099389 [32000/50000]\n",
      "loss: 0.051415 [38400/50000]\n",
      "loss: 0.140980 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.750580\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.932498\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.947624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss1, test_res1, test_res2, test_res3 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model1.train()\n",
    "    train_loss1.append(train_loop(o_trainloader, model1, criterion, optimizer1))\n",
    "    model1.eval()\n",
    "    test_res1.append(test_loop(o_testloader, model1, criterion))\n",
    "    test_res2.append(test_loop(s_testloader, model1, criterion))\n",
    "    test_res3.append(test_loop(s4_testloader, model1, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.662874 [    0/50000]\n",
      "loss: 1.308737 [ 6400/50000]\n",
      "loss: 0.988552 [12800/50000]\n",
      "loss: 0.864831 [19200/50000]\n",
      "loss: 1.072334 [25600/50000]\n",
      "loss: 1.101029 [32000/50000]\n",
      "loss: 0.801965 [38400/50000]\n",
      "loss: 1.007986 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.744969\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.730300\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.010105\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.677301 [    0/50000]\n",
      "loss: 0.677508 [ 6400/50000]\n",
      "loss: 0.680570 [12800/50000]\n",
      "loss: 0.533542 [19200/50000]\n",
      "loss: 0.681395 [25600/50000]\n",
      "loss: 0.453342 [32000/50000]\n",
      "loss: 0.494698 [38400/50000]\n",
      "loss: 0.584859 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.679132\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.681713\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 1.010048\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.618595 [    0/50000]\n",
      "loss: 0.526997 [ 6400/50000]\n",
      "loss: 0.635499 [12800/50000]\n",
      "loss: 0.614956 [19200/50000]\n",
      "loss: 0.587704 [25600/50000]\n",
      "loss: 0.556194 [32000/50000]\n",
      "loss: 0.499377 [38400/50000]\n",
      "loss: 0.657495 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.614790\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.634517\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.042532\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.440453 [    0/50000]\n",
      "loss: 0.401524 [ 6400/50000]\n",
      "loss: 0.657518 [12800/50000]\n",
      "loss: 0.394756 [19200/50000]\n",
      "loss: 0.412695 [25600/50000]\n",
      "loss: 0.458245 [32000/50000]\n",
      "loss: 0.455497 [38400/50000]\n",
      "loss: 0.482684 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.705568\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.675919\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.032282\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.442654 [    0/50000]\n",
      "loss: 0.339367 [ 6400/50000]\n",
      "loss: 0.256119 [12800/50000]\n",
      "loss: 0.233662 [19200/50000]\n",
      "loss: 0.531077 [25600/50000]\n",
      "loss: 0.345663 [32000/50000]\n",
      "loss: 0.472143 [38400/50000]\n",
      "loss: 0.303986 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.566849\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.630997\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.177225\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.262456 [    0/50000]\n",
      "loss: 0.310774 [ 6400/50000]\n",
      "loss: 0.351558 [12800/50000]\n",
      "loss: 0.362242 [19200/50000]\n",
      "loss: 0.345150 [25600/50000]\n",
      "loss: 0.428592 [32000/50000]\n",
      "loss: 0.275203 [38400/50000]\n",
      "loss: 0.537459 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.589679\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.626404\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.096600\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.142183 [    0/50000]\n",
      "loss: 0.293149 [ 6400/50000]\n",
      "loss: 0.451496 [12800/50000]\n",
      "loss: 0.227865 [19200/50000]\n",
      "loss: 0.228682 [25600/50000]\n",
      "loss: 0.228485 [32000/50000]\n",
      "loss: 0.320262 [38400/50000]\n",
      "loss: 0.273836 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.629893\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.656982\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.161577\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.255061 [    0/50000]\n",
      "loss: 0.063789 [ 6400/50000]\n",
      "loss: 0.527836 [12800/50000]\n",
      "loss: 0.330132 [19200/50000]\n",
      "loss: 0.292275 [25600/50000]\n",
      "loss: 0.146458 [32000/50000]\n",
      "loss: 0.203509 [38400/50000]\n",
      "loss: 0.261101 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.655765\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.677669\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.087546\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.124025 [    0/50000]\n",
      "loss: 0.109433 [ 6400/50000]\n",
      "loss: 0.196871 [12800/50000]\n",
      "loss: 0.110010 [19200/50000]\n",
      "loss: 0.358100 [25600/50000]\n",
      "loss: 0.269637 [32000/50000]\n",
      "loss: 0.122129 [38400/50000]\n",
      "loss: 0.277162 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.786400\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.746664\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.129083\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.098631 [    0/50000]\n",
      "loss: 0.034899 [ 6400/50000]\n",
      "loss: 0.072960 [12800/50000]\n",
      "loss: 0.159409 [19200/50000]\n",
      "loss: 0.115754 [25600/50000]\n",
      "loss: 0.232844 [32000/50000]\n",
      "loss: 0.199023 [38400/50000]\n",
      "loss: 0.111202 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.687412\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.707538\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.121009\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.053523 [    0/50000]\n",
      "loss: 0.173252 [ 6400/50000]\n",
      "loss: 0.135644 [12800/50000]\n",
      "loss: 0.325895 [19200/50000]\n",
      "loss: 0.193416 [25600/50000]\n",
      "loss: 0.139902 [32000/50000]\n",
      "loss: 0.324219 [38400/50000]\n",
      "loss: 0.242449 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.755257\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.755096\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 1.234755\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.099865 [    0/50000]\n",
      "loss: 0.214548 [ 6400/50000]\n",
      "loss: 0.068713 [12800/50000]\n",
      "loss: 0.216244 [19200/50000]\n",
      "loss: 0.325913 [25600/50000]\n",
      "loss: 0.201518 [32000/50000]\n",
      "loss: 0.133187 [38400/50000]\n",
      "loss: 0.168918 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.720023\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.788520\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 1.376706\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.141102 [    0/50000]\n",
      "loss: 0.114634 [ 6400/50000]\n",
      "loss: 0.124361 [12800/50000]\n",
      "loss: 0.190696 [19200/50000]\n",
      "loss: 0.069663 [25600/50000]\n",
      "loss: 0.056939 [32000/50000]\n",
      "loss: 0.118763 [38400/50000]\n",
      "loss: 0.180391 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.777057\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.830887\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.303263\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.074018 [    0/50000]\n",
      "loss: 0.062863 [ 6400/50000]\n",
      "loss: 0.088634 [12800/50000]\n",
      "loss: 0.064077 [19200/50000]\n",
      "loss: 0.160925 [25600/50000]\n",
      "loss: 0.071903 [32000/50000]\n",
      "loss: 0.150870 [38400/50000]\n",
      "loss: 0.309427 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.771635\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.863081\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 1.546927\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.061542 [    0/50000]\n",
      "loss: 0.191643 [ 6400/50000]\n",
      "loss: 0.092277 [12800/50000]\n",
      "loss: 0.135788 [19200/50000]\n",
      "loss: 0.187319 [25600/50000]\n",
      "loss: 0.153170 [32000/50000]\n",
      "loss: 0.077816 [38400/50000]\n",
      "loss: 0.138153 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.812772\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.882784\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.611510\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.098314 [    0/50000]\n",
      "loss: 0.094842 [ 6400/50000]\n",
      "loss: 0.025424 [12800/50000]\n",
      "loss: 0.141678 [19200/50000]\n",
      "loss: 0.136584 [25600/50000]\n",
      "loss: 0.021835 [32000/50000]\n",
      "loss: 0.104810 [38400/50000]\n",
      "loss: 0.134592 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.832314\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.869978\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.429760\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.050236 [    0/50000]\n",
      "loss: 0.005587 [ 6400/50000]\n",
      "loss: 0.105170 [12800/50000]\n",
      "loss: 0.112028 [19200/50000]\n",
      "loss: 0.211956 [25600/50000]\n",
      "loss: 0.020311 [32000/50000]\n",
      "loss: 0.215031 [38400/50000]\n",
      "loss: 0.307446 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.877203\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.894310\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.382753\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.080338 [    0/50000]\n",
      "loss: 0.052126 [ 6400/50000]\n",
      "loss: 0.050265 [12800/50000]\n",
      "loss: 0.066789 [19200/50000]\n",
      "loss: 0.033455 [25600/50000]\n",
      "loss: 0.470418 [32000/50000]\n",
      "loss: 0.061382 [38400/50000]\n",
      "loss: 0.229390 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 2.032413\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 2.228939\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.968488\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.602129 [    0/50000]\n",
      "loss: 0.262436 [ 6400/50000]\n",
      "loss: 0.323405 [12800/50000]\n",
      "loss: 0.157938 [19200/50000]\n",
      "loss: 0.136865 [25600/50000]\n",
      "loss: 0.147639 [32000/50000]\n",
      "loss: 0.070126 [38400/50000]\n",
      "loss: 0.132702 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.779303\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.820161\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.402179\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.071818 [    0/50000]\n",
      "loss: 0.099200 [ 6400/50000]\n",
      "loss: 0.067659 [12800/50000]\n",
      "loss: 0.070964 [19200/50000]\n",
      "loss: 0.062116 [25600/50000]\n",
      "loss: 0.146238 [32000/50000]\n",
      "loss: 0.025029 [38400/50000]\n",
      "loss: 0.045151 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.823996\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.880015\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 1.668205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss2, test_res4, test_res5, test_res6 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model2.train()\n",
    "    train_loss2.append(train_loop(s_trainloader, model2, criterion, optimizer2))\n",
    "    model2.eval()\n",
    "    test_res4.append(test_loop(o_testloader, model2, criterion))\n",
    "    test_res5.append(test_loop(s_testloader, model2, criterion))\n",
    "    test_res6.append(test_loop(s4_testloader, model2, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.570425 [    0/50000]\n",
      "loss: 1.445567 [ 6400/50000]\n",
      "loss: 0.955485 [12800/50000]\n",
      "loss: 1.035960 [19200/50000]\n",
      "loss: 0.945023 [25600/50000]\n",
      "loss: 1.057030 [32000/50000]\n",
      "loss: 0.929975 [38400/50000]\n",
      "loss: 1.059534 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.022390\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.960465\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.987490\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.940887 [    0/50000]\n",
      "loss: 0.740345 [ 6400/50000]\n",
      "loss: 0.700467 [12800/50000]\n",
      "loss: 0.829116 [19200/50000]\n",
      "loss: 0.743836 [25600/50000]\n",
      "loss: 0.966560 [32000/50000]\n",
      "loss: 0.641405 [38400/50000]\n",
      "loss: 0.899982 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.928256\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.833462\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.846687\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.526920 [    0/50000]\n",
      "loss: 0.612579 [ 6400/50000]\n",
      "loss: 0.820902 [12800/50000]\n",
      "loss: 0.948526 [19200/50000]\n",
      "loss: 0.566788 [25600/50000]\n",
      "loss: 0.746605 [32000/50000]\n",
      "loss: 0.632473 [38400/50000]\n",
      "loss: 0.770136 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.787987\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.762476\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.853227\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.620614 [    0/50000]\n",
      "loss: 0.606814 [ 6400/50000]\n",
      "loss: 0.649286 [12800/50000]\n",
      "loss: 0.660000 [19200/50000]\n",
      "loss: 0.599596 [25600/50000]\n",
      "loss: 0.394234 [32000/50000]\n",
      "loss: 0.729898 [38400/50000]\n",
      "loss: 0.572411 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.868379\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.800654\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.803998\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.364319 [    0/50000]\n",
      "loss: 0.645836 [ 6400/50000]\n",
      "loss: 0.477752 [12800/50000]\n",
      "loss: 0.529509 [19200/50000]\n",
      "loss: 0.450018 [25600/50000]\n",
      "loss: 0.567644 [32000/50000]\n",
      "loss: 0.445596 [38400/50000]\n",
      "loss: 0.513149 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.837785\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.780876\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.846343\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.460935 [    0/50000]\n",
      "loss: 0.288818 [ 6400/50000]\n",
      "loss: 0.447755 [12800/50000]\n",
      "loss: 0.557264 [19200/50000]\n",
      "loss: 0.369174 [25600/50000]\n",
      "loss: 0.488251 [32000/50000]\n",
      "loss: 0.312855 [38400/50000]\n",
      "loss: 0.488227 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.807007\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.748019\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.829259\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.227365 [    0/50000]\n",
      "loss: 0.547295 [ 6400/50000]\n",
      "loss: 0.391492 [12800/50000]\n",
      "loss: 0.257526 [19200/50000]\n",
      "loss: 0.354749 [25600/50000]\n",
      "loss: 0.318711 [32000/50000]\n",
      "loss: 0.257714 [38400/50000]\n",
      "loss: 0.400324 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.998907\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.901363\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.927666\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.382153 [    0/50000]\n",
      "loss: 0.298160 [ 6400/50000]\n",
      "loss: 0.361616 [12800/50000]\n",
      "loss: 0.379883 [19200/50000]\n",
      "loss: 0.346451 [25600/50000]\n",
      "loss: 0.377296 [32000/50000]\n",
      "loss: 0.342486 [38400/50000]\n",
      "loss: 0.294431 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.850923\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.788643\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.862870\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.270025 [    0/50000]\n",
      "loss: 0.186548 [ 6400/50000]\n",
      "loss: 0.419516 [12800/50000]\n",
      "loss: 0.351670 [19200/50000]\n",
      "loss: 0.274080 [25600/50000]\n",
      "loss: 0.272504 [32000/50000]\n",
      "loss: 0.295372 [38400/50000]\n",
      "loss: 0.358986 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.936106\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.862949\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.914414\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.164627 [    0/50000]\n",
      "loss: 0.236491 [ 6400/50000]\n",
      "loss: 0.182453 [12800/50000]\n",
      "loss: 0.264042 [19200/50000]\n",
      "loss: 0.141307 [25600/50000]\n",
      "loss: 0.216533 [32000/50000]\n",
      "loss: 0.125307 [38400/50000]\n",
      "loss: 0.198134 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 1.002048\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.904902\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.899004\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.102481 [    0/50000]\n",
      "loss: 0.149603 [ 6400/50000]\n",
      "loss: 0.075706 [12800/50000]\n",
      "loss: 0.197371 [19200/50000]\n",
      "loss: 0.359130 [25600/50000]\n",
      "loss: 0.208839 [32000/50000]\n",
      "loss: 0.157620 [38400/50000]\n",
      "loss: 0.118640 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.945044\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.895225\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.983803\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.047627 [    0/50000]\n",
      "loss: 0.181753 [ 6400/50000]\n",
      "loss: 0.257802 [12800/50000]\n",
      "loss: 0.131738 [19200/50000]\n",
      "loss: 0.065819 [25600/50000]\n",
      "loss: 0.290168 [32000/50000]\n",
      "loss: 0.229848 [38400/50000]\n",
      "loss: 0.124572 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.902858\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.865940\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 1.021453\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.144652 [    0/50000]\n",
      "loss: 0.247971 [ 6400/50000]\n",
      "loss: 0.045856 [12800/50000]\n",
      "loss: 0.226797 [19200/50000]\n",
      "loss: 0.072639 [25600/50000]\n",
      "loss: 0.215471 [32000/50000]\n",
      "loss: 0.090868 [38400/50000]\n",
      "loss: 0.247502 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 1.065506\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.960295\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.986477\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.050795 [    0/50000]\n",
      "loss: 0.139897 [ 6400/50000]\n",
      "loss: 0.096772 [12800/50000]\n",
      "loss: 0.086029 [19200/50000]\n",
      "loss: 0.257472 [25600/50000]\n",
      "loss: 0.304396 [32000/50000]\n",
      "loss: 0.221652 [38400/50000]\n",
      "loss: 0.255871 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 1.061042\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 1.002690\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 1.086508\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.233111 [    0/50000]\n",
      "loss: 0.139415 [ 6400/50000]\n",
      "loss: 0.053666 [12800/50000]\n",
      "loss: 0.093678 [19200/50000]\n",
      "loss: 0.065330 [25600/50000]\n",
      "loss: 0.128120 [32000/50000]\n",
      "loss: 0.058998 [38400/50000]\n",
      "loss: 0.134286 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 1.060719\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.989334\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 1.140099\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.085464 [    0/50000]\n",
      "loss: 0.121921 [ 6400/50000]\n",
      "loss: 0.158944 [12800/50000]\n",
      "loss: 0.320550 [19200/50000]\n",
      "loss: 0.057209 [25600/50000]\n",
      "loss: 0.143146 [32000/50000]\n",
      "loss: 0.068513 [38400/50000]\n",
      "loss: 0.119720 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 1.306914\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 1.126514\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.074918\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.142545 [    0/50000]\n",
      "loss: 0.174180 [ 6400/50000]\n",
      "loss: 0.086964 [12800/50000]\n",
      "loss: 0.163706 [19200/50000]\n",
      "loss: 0.072189 [25600/50000]\n",
      "loss: 0.106225 [32000/50000]\n",
      "loss: 0.162154 [38400/50000]\n",
      "loss: 0.019847 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.156325\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.028042\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 1.066395\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.059157 [    0/50000]\n",
      "loss: 0.124243 [ 6400/50000]\n",
      "loss: 0.178676 [12800/50000]\n",
      "loss: 0.111086 [19200/50000]\n",
      "loss: 0.084521 [25600/50000]\n",
      "loss: 0.063472 [32000/50000]\n",
      "loss: 0.158774 [38400/50000]\n",
      "loss: 0.140763 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 1.134609\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.006054\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 1.065266\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.081718 [    0/50000]\n",
      "loss: 0.032890 [ 6400/50000]\n",
      "loss: 0.610609 [12800/50000]\n",
      "loss: 0.311816 [19200/50000]\n",
      "loss: 0.399317 [25600/50000]\n",
      "loss: 0.241468 [32000/50000]\n",
      "loss: 0.059718 [38400/50000]\n",
      "loss: 0.078327 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 1.213431\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.089326\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.081780\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.011220 [    0/50000]\n",
      "loss: 0.051986 [ 6400/50000]\n",
      "loss: 0.094320 [12800/50000]\n",
      "loss: 0.088295 [19200/50000]\n",
      "loss: 0.063628 [25600/50000]\n",
      "loss: 0.098712 [32000/50000]\n",
      "loss: 0.250319 [38400/50000]\n",
      "loss: 0.039490 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 1.276640\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.157052\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 1.192539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss3, test_res7, test_res8, test_res9 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model3.train()\n",
    "    train_loss3.append(train_loop(s4_trainloader, model3, criterion, optimizer3))\n",
    "    model3.eval()\n",
    "    test_res7.append(test_loop(o_testloader, model3, criterion))\n",
    "    test_res8.append(test_loop(s_testloader, model3, criterion))\n",
    "    test_res9.append(test_loop(s4_testloader, model3, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for Testing with original datasets\n",
      "[[891.0, 258.0, 109.0, 8742.0], [876.0, 80.0, 124.0, 8920.0], [810.0, 269.0, 190.0, 8731.0], [721.0, 439.0, 279.0, 8561.0], [760.0, 157.0, 240.0, 8843.0], [622.0, 130.0, 378.0, 8870.0], [791.0, 78.0, 209.0, 8922.0], [889.0, 206.0, 111.0, 8794.0], [880.0, 80.0, 120.0, 8920.0], [913.0, 150.0, 87.0, 8850.0]] [[861.0, 248.0, 139.0, 8752.0], [772.0, 81.0, 228.0, 8919.0], [763.0, 348.0, 237.0, 8652.0], [664.0, 518.0, 336.0, 8482.0], [721.0, 291.0, 279.0, 8709.0], [610.0, 206.0, 390.0, 8794.0], [575.0, 33.0, 425.0, 8967.0], [873.0, 295.0, 127.0, 8705.0], [871.0, 114.0, 129.0, 8886.0], [896.0, 260.0, 104.0, 8740.0]] [[712.0, 321.0, 288.0, 8679.0], [503.0, 78.0, 497.0, 8922.0], [564.0, 398.0, 436.0, 8602.0], [564.0, 815.0, 436.0, 8185.0], [713.0, 690.0, 287.0, 8310.0], [509.0, 371.0, 491.0, 8629.0], [252.0, 29.0, 748.0, 8971.0], [642.0, 128.0, 358.0, 8872.0], [856.0, 449.0, 144.0, 8551.0], [812.0, 594.0, 188.0, 8406.0]]\n",
      "Result for Testing with original datasets\n",
      "[[909.0, 319.0, 91.0, 8681.0], [909.0, 134.0, 91.0, 8866.0], [790.0, 401.0, 210.0, 8599.0], [374.0, 118.0, 626.0, 8882.0], [710.0, 175.0, 290.0, 8825.0], [685.0, 290.0, 315.0, 8710.0], [931.0, 444.0, 69.0, 8556.0], [818.0, 114.0, 182.0, 8886.0], [864.0, 90.0, 136.0, 8910.0], [827.0, 98.0, 173.0, 8902.0]] [[891.0, 261.0, 109.0, 8739.0], [873.0, 88.0, 127.0, 8912.0], [753.0, 327.0, 247.0, 8673.0], [383.0, 164.0, 617.0, 8836.0], [760.0, 256.0, 240.0, 8744.0], [735.0, 393.0, 265.0, 8607.0], [887.0, 261.0, 113.0, 8739.0], [827.0, 155.0, 173.0, 8845.0], [887.0, 92.0, 113.0, 8908.0], [871.0, 136.0, 129.0, 8864.0]] [[767.0, 314.0, 233.0, 8686.0], [639.0, 102.0, 361.0, 8898.0], [621.0, 390.0, 379.0, 8610.0], [597.0, 704.0, 403.0, 8296.0], [709.0, 477.0, 291.0, 8523.0], [587.0, 382.0, 413.0, 8618.0], [509.0, 83.0, 491.0, 8917.0], [666.0, 139.0, 334.0, 8861.0], [795.0, 267.0, 205.0, 8733.0], [834.0, 418.0, 166.0, 8582.0]]\n",
      "Result for Testing with original datasets\n",
      "[[947.0, 967.0, 53.0, 8033.0], [869.0, 141.0, 131.0, 8859.0], [647.0, 354.0, 353.0, 8646.0], [467.0, 277.0, 533.0, 8723.0], [560.0, 91.0, 440.0, 8909.0], [498.0, 131.0, 502.0, 8869.0], [798.0, 362.0, 202.0, 8638.0], [848.0, 307.0, 152.0, 8693.0], [803.0, 62.0, 197.0, 8938.0], [779.0, 92.0, 221.0, 8908.0]] [[928.0, 769.0, 72.0, 8231.0], [861.0, 131.0, 139.0, 8869.0], [643.0, 289.0, 357.0, 8711.0], [501.0, 313.0, 499.0, 8687.0], [595.0, 110.0, 405.0, 8890.0], [588.0, 181.0, 412.0, 8819.0], [813.0, 310.0, 187.0, 8690.0], [877.0, 310.0, 123.0, 8690.0], [820.0, 67.0, 180.0, 8933.0], [781.0, 113.0, 219.0, 8887.0]] [[872.0, 475.0, 128.0, 8525.0], [810.0, 112.0, 190.0, 8888.0], [635.0, 284.0, 365.0, 8716.0], [536.0, 394.0, 464.0, 8606.0], [642.0, 236.0, 358.0, 8764.0], [617.0, 294.0, 383.0, 8706.0], [781.0, 252.0, 219.0, 8748.0], [861.0, 340.0, 139.0, 8660.0], [816.0, 96.0, 184.0, 8904.0], [790.0, 157.0, 210.0, 8843.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res1), max(test_res2), max(test_res3))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res4), max(test_res5), max(test_res6))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res7), max(test_res8), max(test_res9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_acc_finder(test_res):\n",
    "    best, max = 0, 0\n",
    "    for i in range(len(test_res)):\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for j in range(len(test_res[i])):\n",
    "            correct = test_res[i][j][0] +  test_res[i][j][3]\n",
    "            total = correct + test_res[i][j][2] + test_res[i][j][1]\n",
    "            if max < (correct / total):\n",
    "                max = correct / total\n",
    "                best = i\n",
    "\n",
    "    print(f\"best accuary: {max:>0.2f} at {best}\")\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 14\n",
      "best accuary: 0.98 at 16\n",
      "best accuary: 0.95 at 16\n",
      "best accuary: 0.98 at 19\n",
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.96 at 15\n",
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.97 at 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_finder(test_res1)\n",
    "best_acc_finder(test_res2)\n",
    "best_acc_finder(test_res3)\n",
    "best_acc_finder(test_res4)\n",
    "best_acc_finder(test_res5)\n",
    "best_acc_finder(test_res6)\n",
    "best_acc_finder(test_res7)\n",
    "best_acc_finder(test_res8)\n",
    "best_acc_finder(test_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 14\n",
      "(0.9653, 0.8296794298094333, 0.8265, 0.8269203951828071)\n",
      "best accuary: 0.98 at 16\n",
      "(0.9545199999999999, 0.7826007477946206, 0.7726, 0.7746791582146295)\n",
      "best accuary: 0.95 at 16\n",
      "(0.9229200000000001, 0.6712399467604688, 0.6145999999999999, 0.6133574540872406)\n",
      "best accuary: 0.98 at 19\n",
      "(0.96472, 0.8258310831679866, 0.8235999999999999, 0.8237786149548822)\n",
      "best accuary: 0.98 at 8\n",
      "(0.95734, 0.7864677381535649, 0.7867000000000001, 0.7807146671894369)\n",
      "best accuary: 0.96 at 15\n",
      "(0.9390000000000001, 0.7268082722512336, 0.6950000000000001, 0.6981558167402382)\n",
      "best accuary: 0.98 at 8\n",
      "(0.9507999999999999, 0.7594597036368742, 0.7540000000000001, 0.7483880924195984)\n",
      "best accuary: 0.98 at 8\n",
      "(0.9539200000000001, 0.7703511451202903, 0.7696, 0.7657774720834494)\n",
      "best accuary: 0.97 at 17\n",
      "(0.9494999999999999, 0.7513386829324096, 0.7474999999999999, 0.7488944905407856)\n"
     ]
    }
   ],
   "source": [
    "def metrics_single_class(conf_mat):\n",
    "    accuracy = (conf_mat[0] + conf_mat[3]) / (conf_mat[0] + conf_mat[1] + conf_mat[2] + conf_mat[3])\n",
    "    precision = conf_mat[0] / (conf_mat[0] + conf_mat[1])\n",
    "    recall = conf_mat[0] / (conf_mat[0] + conf_mat[2])\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def metrics(conf_mats):\n",
    "    sum_acc, sum_pre, sum_recall, sum_f1 = 0.0, 0.0, 0.0, 0.0\n",
    "    for i in range(len(conf_mats)):\n",
    "        temp_acc, temp_pre, temp_recall, temp_f1 = metrics_single_class(conf_mats[i])\n",
    "        #print(f\"For class-{i}:\\n Accuracy: {temp_acc:>0.4f}, Precision: {temp_pre:>0.4f}, Recall: {temp_recall:>0.4f}, F1-score: {temp_f1:>0.4f}\")\n",
    "        sum_acc += temp_acc\n",
    "        sum_pre += temp_pre\n",
    "        sum_recall += temp_recall\n",
    "        sum_f1 += temp_f1\n",
    "\n",
    "    sum_acc /= 10\n",
    "    sum_pre /= 10\n",
    "    sum_recall /= 10\n",
    "    sum_f1 /= 10\n",
    "\n",
    "    return sum_acc, sum_pre, sum_recall, sum_f1\n",
    "\n",
    "\n",
    "print(metrics(test_res1[best_acc_finder(test_res1)]))\n",
    "print(metrics(test_res2[best_acc_finder(test_res2)]))\n",
    "print(metrics(test_res3[best_acc_finder(test_res3)]))\n",
    "print(metrics(test_res4[best_acc_finder(test_res4)]))\n",
    "print(metrics(test_res5[best_acc_finder(test_res5)]))\n",
    "print(metrics(test_res6[best_acc_finder(test_res6)]))\n",
    "print(metrics(test_res7[best_acc_finder(test_res7)]))\n",
    "print(metrics(test_res8[best_acc_finder(test_res8)]))\n",
    "print(metrics(test_res9[best_acc_finder(test_res9)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bc9c0d9ed678a9439887435d1dc6423dbc20cda066c045b53c2a9575a7c6ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
