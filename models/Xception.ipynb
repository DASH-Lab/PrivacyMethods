{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "## to get pretrained model from timm\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xception(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU(inplace=True)\n",
       "  (block1): Block(\n",
       "    (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rep): Sequential(\n",
       "      (0): SeparableConv2d(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (block2): Block(\n",
       "    (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (block3): Block(\n",
       "    (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (block4): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block5): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block6): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block7): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block8): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block9): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block10): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block11): Block(\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block12): Block(\n",
       "    (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rep): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (conv3): SeparableConv2d(\n",
       "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "    (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act3): ReLU(inplace=True)\n",
       "  (conv4): SeparableConv2d(\n",
       "    (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "    (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act4): ReLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))\n",
    "])\n",
    "\n",
    "root = '' ## 이미지 경로\n",
    "\n",
    "original_trainset = datasets.ImageFolder(root=root+\"/origin-cifar-10/train\", transform=trans)\n",
    "original_testset = datasets.ImageFolder(root=root+\"origin-cifar-10/test\", transform=trans)\n",
    "svd_trainset = datasets.ImageFolder(root=root+\"/svd-cifar-10/train\", transform=trans)\n",
    "svd_testset = datasets.ImageFolder(root=root+\"/svd-cifar-10/test\", transform=trans)\n",
    "svd4_trainset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/train\", transform=trans)\n",
    "svd4_testset = datasets.ImageFolder(root=root+\"/svd4-cifar-10/test\", transform=trans)\n",
    "\n",
    "o_trainloader = DataLoader(original_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "o_testloader = DataLoader(original_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s_trainloader = DataLoader(svd_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s_testloader = DataLoader(svd_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "s4_trainloader = DataLoader(svd4_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "s4_testloader = DataLoader(svd4_testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "classes = original_testset.classes\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model1 = timm.create_model('xception', pretrained=True)\n",
    "model2 = timm.create_model('xception', pretrained=True)\n",
    "model3 = timm.create_model('xception', pretrained=True)\n",
    "\n",
    "model1.fc = nn.Linear(in_features=model1.fc.in_features, out_features=10, bias=True)\n",
    "model2.fc = nn.Linear(in_features=model2.fc.in_features, out_features=10, bias=True)\n",
    "model3.fc = nn.Linear(in_features=model3.fc.in_features, out_features=10, bias=True)\n",
    "\n",
    "nn.init.xavier_normal_(model1.fc.weight)\n",
    "nn.init.xavier_normal_(model2.fc.weight)\n",
    "nn.init.xavier_normal_(model3.fc.weight)\n",
    "\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=lr)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=lr)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_sum = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.to(device))\n",
    "        loss = criterion(pred, y.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            loss_sum += loss\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss_sum / size\n",
    "\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    hit, loss = 0, 0\n",
    "    conf_matrix = []\n",
    "    for i in range(10):\n",
    "        conf_matrix.append([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            loss += criterion(pred, y.to(device)).item()\n",
    "            hit += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "            temp = pred.argmax(1)\n",
    "            for k in range(len(temp)):\n",
    "                for i in range(10):\n",
    "                    if i == temp[k]:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][0] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][1] += 1.0\n",
    "                    else:\n",
    "                        if i == y[k]:\n",
    "                            conf_matrix[i][2] += 1.0\n",
    "                        else:\n",
    "                            conf_matrix[i][3] += 1.0\n",
    "\n",
    "    \n",
    "    loss /= (size/batch_size)\n",
    "    hit /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*hit):>0.1f}%, Avg loss: {loss:>8f}\\n\")\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.313750 [    0/50000]\n",
      "loss: 2.320264 [ 6400/50000]\n",
      "loss: 1.600534 [12800/50000]\n",
      "loss: 1.278136 [19200/50000]\n",
      "loss: 1.041227 [25600/50000]\n",
      "loss: 0.931858 [32000/50000]\n",
      "loss: 0.874596 [38400/50000]\n",
      "loss: 0.925266 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.861171\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.008877\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.375887\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.888448 [    0/50000]\n",
      "loss: 0.824346 [ 6400/50000]\n",
      "loss: 0.574079 [12800/50000]\n",
      "loss: 0.880633 [19200/50000]\n",
      "loss: 0.987906 [25600/50000]\n",
      "loss: 0.740143 [32000/50000]\n",
      "loss: 0.591463 [38400/50000]\n",
      "loss: 0.636473 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.636795\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.758818\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.190953\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.433199 [    0/50000]\n",
      "loss: 0.573900 [ 6400/50000]\n",
      "loss: 0.572995 [12800/50000]\n",
      "loss: 0.499318 [19200/50000]\n",
      "loss: 0.566191 [25600/50000]\n",
      "loss: 0.261863 [32000/50000]\n",
      "loss: 0.442593 [38400/50000]\n",
      "loss: 0.333863 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.607775\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.724731\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.237575\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.606681 [    0/50000]\n",
      "loss: 0.427549 [ 6400/50000]\n",
      "loss: 0.322277 [12800/50000]\n",
      "loss: 0.543598 [19200/50000]\n",
      "loss: 0.360446 [25600/50000]\n",
      "loss: 0.277544 [32000/50000]\n",
      "loss: 0.480681 [38400/50000]\n",
      "loss: 0.419536 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.613629\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.740594\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.426538\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.129718 [    0/50000]\n",
      "loss: 0.210238 [ 6400/50000]\n",
      "loss: 0.340008 [12800/50000]\n",
      "loss: 0.380642 [19200/50000]\n",
      "loss: 0.424680 [25600/50000]\n",
      "loss: 0.388070 [32000/50000]\n",
      "loss: 0.171367 [38400/50000]\n",
      "loss: 0.152014 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.616318\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.735443\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.204705\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.177159 [    0/50000]\n",
      "loss: 0.188576 [ 6400/50000]\n",
      "loss: 0.050797 [12800/50000]\n",
      "loss: 0.354446 [19200/50000]\n",
      "loss: 0.186764 [25600/50000]\n",
      "loss: 0.123638 [32000/50000]\n",
      "loss: 0.564290 [38400/50000]\n",
      "loss: 0.301355 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.609022\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.770756\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.521824\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.098617 [    0/50000]\n",
      "loss: 0.058220 [ 6400/50000]\n",
      "loss: 0.139190 [12800/50000]\n",
      "loss: 0.124760 [19200/50000]\n",
      "loss: 0.246800 [25600/50000]\n",
      "loss: 0.157139 [32000/50000]\n",
      "loss: 0.411576 [38400/50000]\n",
      "loss: 0.254938 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.660038\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.871205\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.786648\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.056846 [    0/50000]\n",
      "loss: 0.225282 [ 6400/50000]\n",
      "loss: 0.094370 [12800/50000]\n",
      "loss: 0.172566 [19200/50000]\n",
      "loss: 0.255546 [25600/50000]\n",
      "loss: 0.083838 [32000/50000]\n",
      "loss: 0.134005 [38400/50000]\n",
      "loss: 0.182250 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.687632\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.873059\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.784963\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.112294 [    0/50000]\n",
      "loss: 0.022117 [ 6400/50000]\n",
      "loss: 0.100384 [12800/50000]\n",
      "loss: 0.238143 [19200/50000]\n",
      "loss: 0.259799 [25600/50000]\n",
      "loss: 0.179437 [32000/50000]\n",
      "loss: 0.168215 [38400/50000]\n",
      "loss: 0.031201 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.674601\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.864754\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 1.703050\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.032594 [    0/50000]\n",
      "loss: 0.101362 [ 6400/50000]\n",
      "loss: 0.158747 [12800/50000]\n",
      "loss: 0.189721 [19200/50000]\n",
      "loss: 0.021561 [25600/50000]\n",
      "loss: 0.128224 [32000/50000]\n",
      "loss: 0.164224 [38400/50000]\n",
      "loss: 0.096372 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.804089\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.037284\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 1.994096\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.038341 [    0/50000]\n",
      "loss: 0.118139 [ 6400/50000]\n",
      "loss: 0.078088 [12800/50000]\n",
      "loss: 0.088701 [19200/50000]\n",
      "loss: 0.067558 [25600/50000]\n",
      "loss: 0.102313 [32000/50000]\n",
      "loss: 0.043130 [38400/50000]\n",
      "loss: 0.108880 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.721707\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.901607\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.742619\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.042648 [    0/50000]\n",
      "loss: 0.006838 [ 6400/50000]\n",
      "loss: 0.050583 [12800/50000]\n",
      "loss: 0.027524 [19200/50000]\n",
      "loss: 0.048694 [25600/50000]\n",
      "loss: 0.070512 [32000/50000]\n",
      "loss: 0.068697 [38400/50000]\n",
      "loss: 0.116384 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.762580\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.000446\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.901836\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.072599 [    0/50000]\n",
      "loss: 0.067754 [ 6400/50000]\n",
      "loss: 0.034374 [12800/50000]\n",
      "loss: 0.018404 [19200/50000]\n",
      "loss: 0.213558 [25600/50000]\n",
      "loss: 0.100216 [32000/50000]\n",
      "loss: 0.052365 [38400/50000]\n",
      "loss: 0.070465 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.792830\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.953150\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.825735\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.012029 [    0/50000]\n",
      "loss: 0.085447 [ 6400/50000]\n",
      "loss: 0.088576 [12800/50000]\n",
      "loss: 0.007828 [19200/50000]\n",
      "loss: 0.113013 [25600/50000]\n",
      "loss: 0.163775 [32000/50000]\n",
      "loss: 0.006211 [38400/50000]\n",
      "loss: 0.119289 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.806604\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.995448\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.830333\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.041054 [    0/50000]\n",
      "loss: 0.065617 [ 6400/50000]\n",
      "loss: 0.053001 [12800/50000]\n",
      "loss: 0.023244 [19200/50000]\n",
      "loss: 0.205523 [25600/50000]\n",
      "loss: 0.157081 [32000/50000]\n",
      "loss: 0.010130 [38400/50000]\n",
      "loss: 0.003439 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.950022\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.970253\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.571318\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.090880 [    0/50000]\n",
      "loss: 0.081572 [ 6400/50000]\n",
      "loss: 0.050331 [12800/50000]\n",
      "loss: 0.039877 [19200/50000]\n",
      "loss: 0.022469 [25600/50000]\n",
      "loss: 0.027088 [32000/50000]\n",
      "loss: 0.104676 [38400/50000]\n",
      "loss: 0.015320 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.843341\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.961328\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.798617\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.014023 [    0/50000]\n",
      "loss: 0.032412 [ 6400/50000]\n",
      "loss: 0.058892 [12800/50000]\n",
      "loss: 0.018598 [19200/50000]\n",
      "loss: 0.017843 [25600/50000]\n",
      "loss: 0.084044 [32000/50000]\n",
      "loss: 0.034265 [38400/50000]\n",
      "loss: 0.169006 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.829461\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.041737\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.886732\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.034980 [    0/50000]\n",
      "loss: 0.043485 [ 6400/50000]\n",
      "loss: 0.051289 [12800/50000]\n",
      "loss: 0.035541 [19200/50000]\n",
      "loss: 0.162950 [25600/50000]\n",
      "loss: 0.162931 [32000/50000]\n",
      "loss: 0.013557 [38400/50000]\n",
      "loss: 0.053713 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.838152\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.082388\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 2.201914\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.011269 [    0/50000]\n",
      "loss: 0.124895 [ 6400/50000]\n",
      "loss: 0.021420 [12800/50000]\n",
      "loss: 0.014296 [19200/50000]\n",
      "loss: 0.031829 [25600/50000]\n",
      "loss: 0.018925 [32000/50000]\n",
      "loss: 0.093029 [38400/50000]\n",
      "loss: 0.133171 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.889243\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 1.075710\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.066254\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.039578 [    0/50000]\n",
      "loss: 0.009119 [ 6400/50000]\n",
      "loss: 0.067864 [12800/50000]\n",
      "loss: 0.067455 [19200/50000]\n",
      "loss: 0.014322 [25600/50000]\n",
      "loss: 0.046950 [32000/50000]\n",
      "loss: 0.039611 [38400/50000]\n",
      "loss: 0.183988 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.847883\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 1.079129\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 2.231621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss1, test_res1, test_res2, test_res3 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model1.train()\n",
    "    train_loss1.append(train_loop(o_trainloader, model1, criterion, optimizer1))\n",
    "    model1.eval()\n",
    "    test_res1.append(test_loop(o_testloader, model1, criterion))\n",
    "    test_res2.append(test_loop(s_testloader, model1, criterion))\n",
    "    test_res3.append(test_loop(s4_testloader, model1, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.310410 [    0/50000]\n",
      "loss: 1.611678 [ 6400/50000]\n",
      "loss: 1.601985 [12800/50000]\n",
      "loss: 1.052712 [19200/50000]\n",
      "loss: 0.879269 [25600/50000]\n",
      "loss: 0.938844 [32000/50000]\n",
      "loss: 0.901041 [38400/50000]\n",
      "loss: 0.666927 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.737142\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.775327\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.129648\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.692542 [    0/50000]\n",
      "loss: 0.639382 [ 6400/50000]\n",
      "loss: 0.675053 [12800/50000]\n",
      "loss: 0.859534 [19200/50000]\n",
      "loss: 0.653885 [25600/50000]\n",
      "loss: 0.733180 [32000/50000]\n",
      "loss: 0.586695 [38400/50000]\n",
      "loss: 0.571444 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.619800\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.688778\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.100964\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.394619 [    0/50000]\n",
      "loss: 0.503122 [ 6400/50000]\n",
      "loss: 0.361733 [12800/50000]\n",
      "loss: 0.440063 [19200/50000]\n",
      "loss: 0.660174 [25600/50000]\n",
      "loss: 0.415920 [32000/50000]\n",
      "loss: 0.606719 [38400/50000]\n",
      "loss: 0.450127 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.658307\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.666908\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.939286\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.314714 [    0/50000]\n",
      "loss: 0.376795 [ 6400/50000]\n",
      "loss: 0.462839 [12800/50000]\n",
      "loss: 0.310382 [19200/50000]\n",
      "loss: 0.646864 [25600/50000]\n",
      "loss: 0.548961 [32000/50000]\n",
      "loss: 0.708571 [38400/50000]\n",
      "loss: 0.273234 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.616197\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.651467\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.139114\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.273606 [    0/50000]\n",
      "loss: 0.337486 [ 6400/50000]\n",
      "loss: 0.567346 [12800/50000]\n",
      "loss: 0.197572 [19200/50000]\n",
      "loss: 0.381363 [25600/50000]\n",
      "loss: 0.271378 [32000/50000]\n",
      "loss: 0.313279 [38400/50000]\n",
      "loss: 0.181593 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.640333\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.646633\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.970618\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.206430 [    0/50000]\n",
      "loss: 0.231498 [ 6400/50000]\n",
      "loss: 0.181742 [12800/50000]\n",
      "loss: 0.316776 [19200/50000]\n",
      "loss: 0.350760 [25600/50000]\n",
      "loss: 0.281763 [32000/50000]\n",
      "loss: 0.385468 [38400/50000]\n",
      "loss: 0.256485 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.595792\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.641657\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 1.143396\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.165300 [    0/50000]\n",
      "loss: 0.120174 [ 6400/50000]\n",
      "loss: 0.090130 [12800/50000]\n",
      "loss: 0.188758 [19200/50000]\n",
      "loss: 0.112991 [25600/50000]\n",
      "loss: 0.224514 [32000/50000]\n",
      "loss: 0.079541 [38400/50000]\n",
      "loss: 0.184896 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.728132\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.715339\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.227623\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.135713 [    0/50000]\n",
      "loss: 0.080479 [ 6400/50000]\n",
      "loss: 0.064601 [12800/50000]\n",
      "loss: 0.125249 [19200/50000]\n",
      "loss: 0.194570 [25600/50000]\n",
      "loss: 0.177731 [32000/50000]\n",
      "loss: 0.091789 [38400/50000]\n",
      "loss: 0.107708 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.685592\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.728352\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.218611\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.105596 [    0/50000]\n",
      "loss: 0.242089 [ 6400/50000]\n",
      "loss: 0.212079 [12800/50000]\n",
      "loss: 0.138889 [19200/50000]\n",
      "loss: 0.052326 [25600/50000]\n",
      "loss: 0.075419 [32000/50000]\n",
      "loss: 0.470065 [38400/50000]\n",
      "loss: 0.321378 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.722809\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.787274\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.443920\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.025608 [    0/50000]\n",
      "loss: 0.029234 [ 6400/50000]\n",
      "loss: 0.207328 [12800/50000]\n",
      "loss: 0.077377 [19200/50000]\n",
      "loss: 0.194921 [25600/50000]\n",
      "loss: 0.100207 [32000/50000]\n",
      "loss: 0.039014 [38400/50000]\n",
      "loss: 0.071593 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.768634\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.788223\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 1.353676\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.200263 [    0/50000]\n",
      "loss: 0.058105 [ 6400/50000]\n",
      "loss: 0.163585 [12800/50000]\n",
      "loss: 0.102423 [19200/50000]\n",
      "loss: 0.105951 [25600/50000]\n",
      "loss: 0.131074 [32000/50000]\n",
      "loss: 0.082518 [38400/50000]\n",
      "loss: 0.070466 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.798076\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.796286\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.283676\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.135201 [    0/50000]\n",
      "loss: 0.122109 [ 6400/50000]\n",
      "loss: 0.103661 [12800/50000]\n",
      "loss: 0.030914 [19200/50000]\n",
      "loss: 0.122794 [25600/50000]\n",
      "loss: 0.057671 [32000/50000]\n",
      "loss: 0.083756 [38400/50000]\n",
      "loss: 0.064795 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.779000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.810938\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.370869\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.056405 [    0/50000]\n",
      "loss: 0.123941 [ 6400/50000]\n",
      "loss: 0.027288 [12800/50000]\n",
      "loss: 0.091544 [19200/50000]\n",
      "loss: 0.123073 [25600/50000]\n",
      "loss: 0.276795 [32000/50000]\n",
      "loss: 0.054172 [38400/50000]\n",
      "loss: 0.075834 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.861591\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.881027\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.509744\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.014735 [    0/50000]\n",
      "loss: 0.139959 [ 6400/50000]\n",
      "loss: 0.073047 [12800/50000]\n",
      "loss: 0.018110 [19200/50000]\n",
      "loss: 0.083048 [25600/50000]\n",
      "loss: 0.053639 [32000/50000]\n",
      "loss: 0.053361 [38400/50000]\n",
      "loss: 0.038445 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.816506\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.861875\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.380798\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.060293 [    0/50000]\n",
      "loss: 0.044538 [ 6400/50000]\n",
      "loss: 0.023086 [12800/50000]\n",
      "loss: 0.153319 [19200/50000]\n",
      "loss: 0.080113 [25600/50000]\n",
      "loss: 0.184728 [32000/50000]\n",
      "loss: 0.107304 [38400/50000]\n",
      "loss: 0.027742 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.918623\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.913422\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.373970\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.028600 [    0/50000]\n",
      "loss: 0.055917 [ 6400/50000]\n",
      "loss: 0.085035 [12800/50000]\n",
      "loss: 0.072863 [19200/50000]\n",
      "loss: 0.114317 [25600/50000]\n",
      "loss: 0.058147 [32000/50000]\n",
      "loss: 0.078771 [38400/50000]\n",
      "loss: 0.140270 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 1.143549\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 1.111410\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.494787\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.036155 [    0/50000]\n",
      "loss: 0.049046 [ 6400/50000]\n",
      "loss: 0.129866 [12800/50000]\n",
      "loss: 0.032195 [19200/50000]\n",
      "loss: 0.075757 [25600/50000]\n",
      "loss: 0.016493 [32000/50000]\n",
      "loss: 0.094600 [38400/50000]\n",
      "loss: 0.093670 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.931202\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.964072\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.581087\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.032397 [    0/50000]\n",
      "loss: 0.028718 [ 6400/50000]\n",
      "loss: 0.035923 [12800/50000]\n",
      "loss: 0.063220 [19200/50000]\n",
      "loss: 0.010537 [25600/50000]\n",
      "loss: 0.097357 [32000/50000]\n",
      "loss: 0.029403 [38400/50000]\n",
      "loss: 0.182134 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.855408\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.877103\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 1.499981\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.170356 [    0/50000]\n",
      "loss: 0.021449 [ 6400/50000]\n",
      "loss: 0.030460 [12800/50000]\n",
      "loss: 0.033699 [19200/50000]\n",
      "loss: 0.029227 [25600/50000]\n",
      "loss: 0.113744 [32000/50000]\n",
      "loss: 0.042607 [38400/50000]\n",
      "loss: 0.085165 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.822060\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.884937\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.530519\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.051074 [    0/50000]\n",
      "loss: 0.099865 [ 6400/50000]\n",
      "loss: 0.032092 [12800/50000]\n",
      "loss: 0.022180 [19200/50000]\n",
      "loss: 0.070355 [25600/50000]\n",
      "loss: 0.026210 [32000/50000]\n",
      "loss: 0.069110 [38400/50000]\n",
      "loss: 0.081044 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.919400\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.992232\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.646248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss2, test_res4, test_res5, test_res6 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model2.train()\n",
    "    train_loss2.append(train_loop(s_trainloader, model2, criterion, optimizer2))\n",
    "    model2.eval()\n",
    "    test_res4.append(test_loop(o_testloader, model2, criterion))\n",
    "    test_res5.append(test_loop(s_testloader, model2, criterion))\n",
    "    test_res6.append(test_loop(s4_testloader, model2, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 2.302337 [    0/50000]\n",
      "loss: 1.886896 [ 6400/50000]\n",
      "loss: 1.598097 [12800/50000]\n",
      "loss: 1.359783 [19200/50000]\n",
      "loss: 1.499762 [25600/50000]\n",
      "loss: 0.965327 [32000/50000]\n",
      "loss: 1.586606 [38400/50000]\n",
      "loss: 0.955674 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.080647\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.012366\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.982286\n",
      "\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.911965 [    0/50000]\n",
      "loss: 1.019206 [ 6400/50000]\n",
      "loss: 0.609681 [12800/50000]\n",
      "loss: 0.919861 [19200/50000]\n",
      "loss: 0.800453 [25600/50000]\n",
      "loss: 0.878897 [32000/50000]\n",
      "loss: 0.762585 [38400/50000]\n",
      "loss: 0.801115 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.921927\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.873085\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.897551\n",
      "\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.852983 [    0/50000]\n",
      "loss: 0.694052 [ 6400/50000]\n",
      "loss: 0.683400 [12800/50000]\n",
      "loss: 0.760138 [19200/50000]\n",
      "loss: 0.798318 [25600/50000]\n",
      "loss: 0.714726 [32000/50000]\n",
      "loss: 0.708544 [38400/50000]\n",
      "loss: 0.608944 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.789547\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.745853\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.790283\n",
      "\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.500952 [    0/50000]\n",
      "loss: 0.487714 [ 6400/50000]\n",
      "loss: 0.531806 [12800/50000]\n",
      "loss: 0.502955 [19200/50000]\n",
      "loss: 0.457823 [25600/50000]\n",
      "loss: 0.612170 [32000/50000]\n",
      "loss: 0.559208 [38400/50000]\n",
      "loss: 0.617808 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.795074\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.742619\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.764977\n",
      "\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.419962 [    0/50000]\n",
      "loss: 0.352733 [ 6400/50000]\n",
      "loss: 0.496276 [12800/50000]\n",
      "loss: 0.293753 [19200/50000]\n",
      "loss: 0.353283 [25600/50000]\n",
      "loss: 0.596161 [32000/50000]\n",
      "loss: 0.700482 [38400/50000]\n",
      "loss: 0.425122 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.835261\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.767223\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.787469\n",
      "\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.245708 [    0/50000]\n",
      "loss: 0.323138 [ 6400/50000]\n",
      "loss: 0.399749 [12800/50000]\n",
      "loss: 0.557141 [19200/50000]\n",
      "loss: 0.317127 [25600/50000]\n",
      "loss: 0.393530 [32000/50000]\n",
      "loss: 0.393568 [38400/50000]\n",
      "loss: 0.224702 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.871818\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.778576\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.813602\n",
      "\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.173845 [    0/50000]\n",
      "loss: 0.259292 [ 6400/50000]\n",
      "loss: 0.168412 [12800/50000]\n",
      "loss: 0.395326 [19200/50000]\n",
      "loss: 0.403821 [25600/50000]\n",
      "loss: 0.155769 [32000/50000]\n",
      "loss: 0.494488 [38400/50000]\n",
      "loss: 0.340827 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.872730\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.798847\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.856124\n",
      "\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.167011 [    0/50000]\n",
      "loss: 0.290790 [ 6400/50000]\n",
      "loss: 0.126585 [12800/50000]\n",
      "loss: 0.325835 [19200/50000]\n",
      "loss: 0.347401 [25600/50000]\n",
      "loss: 0.194267 [32000/50000]\n",
      "loss: 0.185611 [38400/50000]\n",
      "loss: 0.223737 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.841082\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.804457\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.880599\n",
      "\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.068984 [    0/50000]\n",
      "loss: 0.179675 [ 6400/50000]\n",
      "loss: 0.084665 [12800/50000]\n",
      "loss: 0.217065 [19200/50000]\n",
      "loss: 0.303264 [25600/50000]\n",
      "loss: 0.178716 [32000/50000]\n",
      "loss: 0.121497 [38400/50000]\n",
      "loss: 0.272508 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.977774\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.904523\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.964510\n",
      "\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.059343 [    0/50000]\n",
      "loss: 0.077876 [ 6400/50000]\n",
      "loss: 0.136227 [12800/50000]\n",
      "loss: 0.130479 [19200/50000]\n",
      "loss: 0.156557 [25600/50000]\n",
      "loss: 0.229578 [32000/50000]\n",
      "loss: 0.197798 [38400/50000]\n",
      "loss: 0.097110 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 1.158234\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.039790\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.029210\n",
      "\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.071681 [    0/50000]\n",
      "loss: 0.187771 [ 6400/50000]\n",
      "loss: 0.080267 [12800/50000]\n",
      "loss: 0.211740 [19200/50000]\n",
      "loss: 0.101945 [25600/50000]\n",
      "loss: 0.136277 [32000/50000]\n",
      "loss: 0.053702 [38400/50000]\n",
      "loss: 0.157352 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.000816\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.956780\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 1.047350\n",
      "\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.022021 [    0/50000]\n",
      "loss: 0.253427 [ 6400/50000]\n",
      "loss: 0.225720 [12800/50000]\n",
      "loss: 0.129454 [19200/50000]\n",
      "loss: 0.154125 [25600/50000]\n",
      "loss: 0.156138 [32000/50000]\n",
      "loss: 0.085121 [38400/50000]\n",
      "loss: 0.104127 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 1.055761\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 1.020267\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.107132\n",
      "\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.065535 [    0/50000]\n",
      "loss: 0.023183 [ 6400/50000]\n",
      "loss: 0.246374 [12800/50000]\n",
      "loss: 0.076422 [19200/50000]\n",
      "loss: 0.069960 [25600/50000]\n",
      "loss: 0.137043 [32000/50000]\n",
      "loss: 0.143420 [38400/50000]\n",
      "loss: 0.168455 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.010683\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.977859\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 1.083411\n",
      "\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.098902 [    0/50000]\n",
      "loss: 0.055512 [ 6400/50000]\n",
      "loss: 0.184274 [12800/50000]\n",
      "loss: 0.060773 [19200/50000]\n",
      "loss: 0.068840 [25600/50000]\n",
      "loss: 0.125545 [32000/50000]\n",
      "loss: 0.105313 [38400/50000]\n",
      "loss: 0.069196 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 1.144191\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.074651\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.132650\n",
      "\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.072128 [    0/50000]\n",
      "loss: 0.090423 [ 6400/50000]\n",
      "loss: 0.080554 [12800/50000]\n",
      "loss: 0.038376 [19200/50000]\n",
      "loss: 0.029813 [25600/50000]\n",
      "loss: 0.116677 [32000/50000]\n",
      "loss: 0.088654 [38400/50000]\n",
      "loss: 0.059558 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 1.226698\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 1.137292\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 1.126842\n",
      "\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.126890 [    0/50000]\n",
      "loss: 0.076931 [ 6400/50000]\n",
      "loss: 0.067923 [12800/50000]\n",
      "loss: 0.024139 [19200/50000]\n",
      "loss: 0.066564 [25600/50000]\n",
      "loss: 0.121876 [32000/50000]\n",
      "loss: 0.161691 [38400/50000]\n",
      "loss: 0.076166 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.321553\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 1.213841\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.201097\n",
      "\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.099467 [    0/50000]\n",
      "loss: 0.028947 [ 6400/50000]\n",
      "loss: 0.041798 [12800/50000]\n",
      "loss: 0.027160 [19200/50000]\n",
      "loss: 0.149162 [25600/50000]\n",
      "loss: 0.057064 [32000/50000]\n",
      "loss: 0.111430 [38400/50000]\n",
      "loss: 0.041784 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 1.335435\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.213240\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 1.234598\n",
      "\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.074223 [    0/50000]\n",
      "loss: 0.003641 [ 6400/50000]\n",
      "loss: 0.018880 [12800/50000]\n",
      "loss: 0.080153 [19200/50000]\n",
      "loss: 0.065330 [25600/50000]\n",
      "loss: 0.128808 [32000/50000]\n",
      "loss: 0.046530 [38400/50000]\n",
      "loss: 0.084157 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 1.200833\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.115961\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 1.163517\n",
      "\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.045759 [    0/50000]\n",
      "loss: 0.006202 [ 6400/50000]\n",
      "loss: 0.073018 [12800/50000]\n",
      "loss: 0.058676 [19200/50000]\n",
      "loss: 0.157871 [25600/50000]\n",
      "loss: 0.058141 [32000/50000]\n",
      "loss: 0.016123 [38400/50000]\n",
      "loss: 0.018602 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 1.195822\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 1.126593\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.271684\n",
      "\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.037168 [    0/50000]\n",
      "loss: 0.032958 [ 6400/50000]\n",
      "loss: 0.045430 [12800/50000]\n",
      "loss: 0.052760 [19200/50000]\n",
      "loss: 0.033837 [25600/50000]\n",
      "loss: 0.043589 [32000/50000]\n",
      "loss: 0.036165 [38400/50000]\n",
      "loss: 0.067040 [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.193672\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.142069\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 1.223566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss3, test_res7, test_res8, test_res9 = [], [], [], []\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i + 1}-------------------------------\")\n",
    "    model3.train()\n",
    "    train_loss3.append(train_loop(s4_trainloader, model3, criterion, optimizer3))\n",
    "    model3.eval()\n",
    "    test_res7.append(test_loop(o_testloader, model3, criterion))\n",
    "    test_res8.append(test_loop(s_testloader, model3, criterion))\n",
    "    test_res9.append(test_loop(s4_testloader, model3, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for Testing with original datasets\n",
      "[[891.0, 286.0, 109.0, 8714.0], [918.0, 126.0, 82.0, 8874.0], [702.0, 192.0, 298.0, 8808.0], [624.0, 305.0, 376.0, 8695.0], [747.0, 143.0, 253.0, 8857.0], [685.0, 197.0, 315.0, 8803.0], [882.0, 182.0, 118.0, 8818.0], [901.0, 254.0, 99.0, 8746.0], [900.0, 97.0, 100.0, 8903.0], [862.0, 106.0, 138.0, 8894.0]] [[858.0, 238.0, 142.0, 8762.0], [846.0, 83.0, 154.0, 8917.0], [691.0, 232.0, 309.0, 8768.0], [649.0, 439.0, 351.0, 8561.0], [691.0, 174.0, 309.0, 8826.0], [668.0, 262.0, 332.0, 8738.0], [769.0, 132.0, 231.0, 8868.0], [880.0, 255.0, 120.0, 8745.0], [913.0, 153.0, 87.0, 8847.0], [871.0, 196.0, 129.0, 8804.0]] [[665.0, 302.0, 335.0, 8698.0], [326.0, 13.0, 674.0, 8987.0], [472.0, 222.0, 528.0, 8778.0], [676.0, 1016.0, 324.0, 7984.0], [749.0, 678.0, 251.0, 8322.0], [554.0, 462.0, 446.0, 8538.0], [280.0, 24.0, 720.0, 8976.0], [609.0, 94.0, 391.0, 8906.0], [868.0, 555.0, 132.0, 8445.0], [786.0, 649.0, 214.0, 8351.0]]\n",
      "Result for Testing with original datasets\n",
      "[[909.0, 324.0, 91.0, 8676.0], [960.0, 261.0, 40.0, 8739.0], [798.0, 323.0, 202.0, 8677.0], [622.0, 337.0, 378.0, 8663.0], [772.0, 189.0, 228.0, 8811.0], [614.0, 154.0, 386.0, 8846.0], [895.0, 276.0, 105.0, 8724.0], [794.0, 98.0, 206.0, 8902.0], [803.0, 33.0, 197.0, 8967.0], [785.0, 53.0, 215.0, 8947.0]] [[882.0, 275.0, 118.0, 8725.0], [931.0, 205.0, 69.0, 8795.0], [761.0, 311.0, 239.0, 8689.0], [646.0, 386.0, 354.0, 8614.0], [789.0, 264.0, 211.0, 8736.0], [645.0, 207.0, 355.0, 8793.0], [858.0, 210.0, 142.0, 8790.0], [760.0, 105.0, 240.0, 8895.0], [820.0, 50.0, 180.0, 8950.0], [804.0, 91.0, 196.0, 8909.0]] [[762.0, 222.0, 238.0, 8778.0], [816.0, 133.0, 184.0, 8867.0], [655.0, 394.0, 345.0, 8606.0], [662.0, 801.0, 338.0, 8199.0], [813.0, 659.0, 187.0, 8341.0], [469.0, 219.0, 531.0, 8781.0], [576.0, 103.0, 424.0, 8897.0], [563.0, 44.0, 437.0, 8956.0], [844.0, 204.0, 156.0, 8796.0], [818.0, 243.0, 182.0, 8757.0]]\n",
      "Result for Testing with original datasets\n",
      "[[919.0, 589.0, 81.0, 8411.0], [934.0, 306.0, 66.0, 8694.0], [647.0, 249.0, 353.0, 8751.0], [518.0, 405.0, 482.0, 8595.0], [594.0, 121.0, 406.0, 8879.0], [443.0, 98.0, 557.0, 8902.0], [904.0, 491.0, 96.0, 8509.0], [801.0, 185.0, 199.0, 8815.0], [836.0, 107.0, 164.0, 8893.0], [758.0, 95.0, 242.0, 8905.0]] [[916.0, 513.0, 84.0, 8487.0], [923.0, 243.0, 77.0, 8757.0], [655.0, 249.0, 345.0, 8751.0], [543.0, 382.0, 457.0, 8618.0], [670.0, 176.0, 330.0, 8824.0], [502.0, 125.0, 498.0, 8875.0], [899.0, 407.0, 101.0, 8593.0], [816.0, 175.0, 184.0, 8825.0], [832.0, 107.0, 168.0, 8893.0], [775.0, 92.0, 225.0, 8908.0]] [[860.0, 337.0, 140.0, 8663.0], [880.0, 216.0, 120.0, 8784.0], [655.0, 258.0, 345.0, 8742.0], [599.0, 465.0, 401.0, 8535.0], [725.0, 325.0, 275.0, 8675.0], [535.0, 197.0, 465.0, 8803.0], [837.0, 245.0, 163.0, 8755.0], [777.0, 187.0, 223.0, 8813.0], [857.0, 155.0, 143.0, 8845.0], [763.0, 127.0, 237.0, 8873.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res1), max(test_res2), max(test_res3))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res4), max(test_res5), max(test_res6))\n",
    "\n",
    "print(\"Result for Testing with original datasets\")\n",
    "print(max(test_res7), max(test_res8), max(test_res9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_acc_finder(test_res):\n",
    "    best, max = 0, 0\n",
    "    for i in range(len(test_res)):\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for j in range(len(test_res[i])):\n",
    "            correct = test_res[i][j][0] +  test_res[i][j][3]\n",
    "            total = correct + test_res[i][j][2] + test_res[i][j][1]\n",
    "            if max < (correct / total):\n",
    "                max = correct / total\n",
    "                best = i\n",
    "\n",
    "    print(f\"best accuary: {max:>0.2f} at {best}\")\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.98 at 11\n",
      "best accuary: 0.96 at 13\n",
      "best accuary: 0.98 at 15\n",
      "best accuary: 0.98 at 7\n",
      "best accuary: 0.97 at 4\n",
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.98 at 8\n",
      "best accuary: 0.97 at 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_finder(test_res1)\n",
    "best_acc_finder(test_res2)\n",
    "best_acc_finder(test_res3)\n",
    "best_acc_finder(test_res4)\n",
    "best_acc_finder(test_res5)\n",
    "best_acc_finder(test_res6)\n",
    "best_acc_finder(test_res7)\n",
    "best_acc_finder(test_res8)\n",
    "best_acc_finder(test_res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuary: 0.98 at 8\n",
      "(0.96434, 0.8235704590791609, 0.8217000000000001, 0.8216989353969355)\n",
      "best accuary: 0.98 at 11\n",
      "(0.9539, 0.7899591820907047, 0.7695, 0.7711250441640782)\n",
      "best accuary: 0.96 at 13\n",
      "(0.9211200000000002, 0.6748912726487852, 0.6055999999999999, 0.6020618723751362)\n",
      "best accuary: 0.98 at 15\n",
      "(0.9614999999999998, 0.8093928131522722, 0.8075000000000001, 0.8072381684426938)\n",
      "best accuary: 0.98 at 7\n",
      "(0.9603000000000002, 0.808426570019179, 0.8014999999999999, 0.8030111621887046)\n",
      "best accuary: 0.97 at 4\n",
      "(0.93956, 0.7297270599754124, 0.6977999999999999, 0.700065930162623)\n",
      "best accuary: 0.98 at 8\n",
      "(0.9511400000000002, 0.766867454860588, 0.7557, 0.7497770356513755)\n",
      "best accuary: 0.98 at 8\n",
      "(0.9518999999999999, 0.7650450892615127, 0.7595000000000001, 0.7555173730599272)\n",
      "best accuary: 0.97 at 11\n",
      "(0.9489000000000001, 0.7480693854228467, 0.7444999999999999, 0.7449372449749209)\n"
     ]
    }
   ],
   "source": [
    "def metrics_single_class(conf_mat):\n",
    "    accuracy = (conf_mat[0] + conf_mat[3]) / (conf_mat[0] + conf_mat[1] + conf_mat[2] + conf_mat[3])\n",
    "    precision = conf_mat[0] / (conf_mat[0] + conf_mat[1])\n",
    "    recall = conf_mat[0] / (conf_mat[0] + conf_mat[2])\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def metrics(conf_mats):\n",
    "    sum_acc, sum_pre, sum_recall, sum_f1 = 0.0, 0.0, 0.0, 0.0\n",
    "    for i in range(len(conf_mats)):\n",
    "        temp_acc, temp_pre, temp_recall, temp_f1 = metrics_single_class(conf_mats[i])\n",
    "        #print(f\"For class-{i}:\\n Accuracy: {temp_acc:>0.4f}, Precision: {temp_pre:>0.4f}, Recall: {temp_recall:>0.4f}, F1-score: {temp_f1:>0.4f}\")\n",
    "        sum_acc += temp_acc\n",
    "        sum_pre += temp_pre\n",
    "        sum_recall += temp_recall\n",
    "        sum_f1 += temp_f1\n",
    "\n",
    "    sum_acc /= 10\n",
    "    sum_pre /= 10\n",
    "    sum_recall /= 10\n",
    "    sum_f1 /= 10\n",
    "\n",
    "    return sum_acc, sum_pre, sum_recall, sum_f1\n",
    "\n",
    "\n",
    "print(metrics(test_res1[best_acc_finder(test_res1)]))\n",
    "print(metrics(test_res2[best_acc_finder(test_res2)]))\n",
    "print(metrics(test_res3[best_acc_finder(test_res3)]))\n",
    "print(metrics(test_res4[best_acc_finder(test_res4)]))\n",
    "print(metrics(test_res5[best_acc_finder(test_res5)]))\n",
    "print(metrics(test_res6[best_acc_finder(test_res6)]))\n",
    "print(metrics(test_res7[best_acc_finder(test_res7)]))\n",
    "print(metrics(test_res8[best_acc_finder(test_res8)]))\n",
    "print(metrics(test_res9[best_acc_finder(test_res9)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bc9c0d9ed678a9439887435d1dc6423dbc20cda066c045b53c2a9575a7c6ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
